[
  {
    "path": "posts/2023-04-20-automatic-sorting-of-pictures-by-country/",
    "title": "Automatic sorting of pictures by location",
    "description": "I like to make a backup of my pictures on an external drive and keep them tidy by sorting them in a separate folder for each country. In this post I share a small script to automate this process and showcase how to do reverse geocoding offline.",
    "author": [
      {
        "name": "Francesco S. Bellelli",
        "url": {}
      }
    ],
    "date": "2023-04-20",
    "categories": [
      "coding"
    ],
    "contents": "\r\n\r\nContents\r\nIntroduction\r\nExtracting EXIF information\r\nWhat is EXIF data?\r\nExtracting EXIF data from pictures\r\nVisualising extracted coordinates\r\n\r\nReverse geocoding\r\nLoading country border informations\r\nConverting coordinates to countries\r\n\r\nCopying files\r\nConclusion\r\n\r\n\r\n\r\n\r\nFigure 1: image from Caterina Sousa (Pexels)\r\n\r\n\r\n\r\nIntroduction\r\nMost of our photo devices save information on the location in which pictures were shot. This allows your phone gallery to create those nice maps with all your pictures scattered around the globe. So, can we access this information and use it to sort the pictures in an external hard disk? Yes, we can absolutely can do that!\r\nBroadly speaking we can divide our task in 3 fundamental steps:\r\nExtracting geographic information from the picture files\r\nFinding in which country the picture was taken (if you wish to sort by state/province/city this can also be done)\r\nCopying the pictures in a tidy folder structure\r\nIn this tutorial, I will walk you through each step, showing you how to use R to perform each task and automate the sorting of your pictures by location.\r\nExtracting EXIF information\r\nThe first step is to extract the precious geographic information from the picture files. It turns our these are stored in a standardised way in something called EXIF.\r\nWhat is EXIF data?\r\nEXIF (Exchangeable Image File Format) is a standard format for storing metadata in image files used by all digital cameras and smartphones. The EXIF information in a picture file typically includes data about the camera used to take the picture, the date and time the picture was taken, the shutter speed, aperture, ISO, focal length, and other camera settings. Additionally, it can include information about the location where the picture was taken, including the GPS coordinates and altitude. It is precisely these GPS coordinates that we will be using to sort our pictures.\r\nExtracting EXIF data from pictures\r\nThe package exifr can be used to extract EXIF data from the picture files with one line of code. Just a small caveat: in order to work the package requires an installation of perl (a programming language). If you don’t have perl already installed, follow the instructions here to get the latest version. This quite simple to do, it will just require one or two clicks.\r\n\r\n\r\nlibrary(exifr)\r\n\r\n# folder where pictures are located\r\npath_orig <- \"C:/Users/me/EXAMPLE_PICTURE_FOLDER/\"\r\n\r\n# extract GPS coordinates\r\ninfo <- read_exif(path = path_orig,\r\n                  tags = c(\"GPSLatitude\", \"GPSLongitude\"),\r\n                  recursive = T) # If TRUE, this will loop through all the subdirectories in the path\r\n\r\n\r\nThe command above extract the latitude and longitude information for all the pictures in the folder and conveniently return it in a table. If you wish to check what other picture information is stored in the EXIF data, just drop the tags line to see all the 180+ fields available.\r\n\r\n\r\n\r\nVisualising extracted coordinates\r\nNow that we have the latitude and longitude of our pictures’ locations, we can place them on a map to get a bird eye view of the results. The package leaflet provides an easy and interactive maps. Zoom in the map below to see the exact location of my last 2444 photos.\r\n\r\n\r\nlibrary(leaflet)\r\n\r\nleaflet(info) %>%\r\n      addTiles() %>%  # This will add a base layer map from OpenStreetMap\r\n      addCircleMarkers(lng= ~GPSLongitude, lat=~GPSLatitude, # add markers for your photo's location\r\n                       clusterOptions = markerClusterOptions()) # Groups markers together when zooming out \r\n\r\n\r\n\r\nReverse geocoding\r\nReverse geocoding is the process of finding a location or an address from geographic coordinates (latitude and longitude) on a map. It is the inverse of geocoding, which transforms an address into geographic coordinates.\r\nIf you are interested in precise addresses (e.g. street level), then the best approach is to use a reverse geocoding API such as the one offered by Google Maps or OpenStreetMap (check out the packages ggmaps and tidygeocoder if you are interested in these solutions). Be aware that these services often require setting up an account and might involve a cap on the free number of API calls (i.e. a limit on the free number of addresses you can get).\r\nSince we are only interested in knowing the country in which pictures are taken we will take a different approach: we will perform the reverse geocoding offline by levaraging R’s GIS packages. Essentially, this will happen in two steps: Step 1) Load geospatial information on country borders, and Step 2) check in which country the coordinates fall.\r\nNotice that this approach could potentially be extended also to more precise geographic information (e.g. finding out states, counties, provinces) by swapping the data in Step 1 with more granular datasets.\r\nLoading country border informations\r\nGeospatial data on international borders can be downloaded from Natural Earth, a free repository of GIS data. I would recommend going for the 10m country country polygons, which you can download by clicking here. The download will contain a folder with multiple GIS data files. I will now show you how to read this information in R.\r\nIn case you wish to retrieve more precise location information from the pictures, you could consider downloading states or even county polygons (data can be found on this page).\r\nThe easiest way of loading the country information in R is with the package sf, which provides an easy way of manipulating GIS data. You can load the country polygons in R with the commands below.\r\nIn the first line I define the path to the shapefile (the one with the extension .shp). In the second line I read it in R by using the package sf. If you check the object, you will see that it is organised in a table format. Each row corresponds to a country; each column provides information on the country (e.g. population, GDP, different names, etc.). The last column, geometry, contains the actual geospatial information. It is the list of vertices of the polygons describing each country. In the third line of code, I keep only the information on country names and geometries (this will keep it simpler and make the next plot faster).\r\n\r\n\r\nlibrary(sf)\r\n\r\n# path to the shapefile (.shp) containing country borders\r\npath_country_shapefile <- \"EXAMPLE/ne_10m_admin_0_countries/ne_10m_admin_0_countries.shp\" \r\n\r\n# load shapefiles countries\r\ncountries <- read_sf(path_country_shapefile)\r\n  \r\n# keep only info on country name and borders\r\ncountries <- countries[,c(\"NAME_LONG\",\"geometry\")]\r\n\r\n# Now you can easily plot a world map (this might be a bit slow):\r\nplot(countries)\r\n\r\n\r\nConverting coordinates to countries\r\nNow that we have border information, we just need to check in which country our pictures were taken.\r\nThe first command specifies that our latitude and longitude columns are geographic coordinates in the World Geodetic System (WGS84): this is the coordinates and earth representation used by GPS. All that is left to do is check in which country polygon these coordinates are. We can perform this operation with the command st_intersects, which returns the number of the country in which the photo was taken. Finally, we can use this index to import the country name in our info table.\r\n\r\n\r\n# convert info into vector points\r\npoints <- st_as_sf(info[!is.na(info$GPSLatitude),], coords = c(\"GPSLongitude\", \"GPSLatitude\"), crs = \"WGS84\")\r\n  \r\n# intersect points with countries\r\ncountries_noegypt <- countries[-162,] #there seem to be issues with the shape of Egypt, so I will drop it from this demo\r\ncountry_match <- as.data.frame(st_intersects(points, countries_noegypt))\r\n\r\n# add country name to our table of information\r\ninfo$country[!is.na(info$GPSLatitude)][country_match$row.id] <- countries_noegypt$NAME_LONG[country_match$col.id]\r\n\r\n\r\nIn this specific example we had to drop Egypt because there seems to be an issue with its polygon. This could be solved by replacing the border information with data from an alternative source. A quick search reveals many alternative sources (e.g. World Bank, geoBoundaries, University of Pennsylvania, ArcGIS, DIVA-GIS, IPUS, Opendatasoft, IGISMAP). Potentially, one could download just the shapefile for Egypt and intersect the photo location with this file.\r\nCopying files\r\nIf everything worked fine, you should now have a table looking like the one below. All we are left to do is save it in a tidy folder structure.\r\n\r\n\r\nSourceFile\r\nGPSLatitude\r\nGPSLongitude\r\ncountry\r\n100\r\nD:/Backup photos Lily 2023_04_29/Camera/IMG_20210222_091109.jpg\r\n46.41907\r\n6.925791\r\nSwitzerland\r\n1000\r\nD:/Backup photos Lily 2023_04_29/Camera/IMG_20220611_150031.jpg\r\n38.32310\r\n26.302590\r\nTurkey\r\n2200\r\nD:/Backup photos Lily 2023_04_29/Camera/IMG_20230405_212441.jpg\r\n31.63434\r\n-7.985343\r\nMorocco\r\n\r\nThe code below creates a separate folder for each country and copies the photos in the corresponding folder. For countries for which no country was found, a special folder “unknown country” is created. This could happen mainly for two reasons: 1) there is no geospatial coordinates in the EXIF data. 2) When we intersect the coordinate with the country polygon, the point landed outside the country polygon. This may occur next to the sea or large water bodies because the polygons are only a rough representation of a country land outline. If this is the case you may try using the command ´sf_distance´ to find the closest country polygon.\r\nMoreover, if you are close to the poles, a certain degree of distortion is created when the polygons are projected on a flat surface. The intersection operation carried out by ´sf´ are done on a planar projection; the default projection (equirectangular) tends to introduce distortion closer to the poles. You may mitigate this problem by choosing a more suitable projection and applying it to the photo’s coordinates and country polygons with the command st_transform. This is a complex topic: if you want to learn more and understand which projection might serve you best, I highly recommend this FANTASTIC series of articles from the ANZLIC Committee on Surveying and Mapping (ACSM).\r\n\r\n\r\n  # path of the folder where you want to save the pictures\r\n  path_dest <- \"C:/Users/me/EXAMPLE_SORTED/\"\r\n\r\n  # if there is any photo for which we did not manage to identify the country, tag it as \"unknown country\"\r\n  info$country <- ifelse(is.na(info$country), \"unknown country\", info$country)\r\n  \r\n  #make list of all countries (this is used to create folders for each countries)\r\n  countries_photos <- unique(info$country)\r\n  \r\n  # copy the pictures in the the destination directory\r\n  for (i in countries_photos){\r\n    \r\n    cat(paste0(\"\\rCopying pictures for country \", match(i, countries_photos), \"/\", length(countries_photos), \": \", i, paste0(rep(\" \",30), collapse = \"\")))\r\n    \r\n    # create a directory for each country for which there are pictures\r\n    if (!dir.exists(paste0(path_dest, i))){\r\n      dir.create(paste0(path_dest, i))\r\n    }\r\n    \r\n    # copy the picture in the destination directory\r\n    temp <- info[info$country == i, ]\r\n    file.copy(from= temp$SourceFile, to= paste0(path_dest, i), \r\n              overwrite = FALSE, recursive = FALSE, \r\n              copy.date = TRUE)\r\n    \r\n  }\r\n\r\n\r\nConclusion\r\nNow you know how to sort you pictures based on the location information saved by our devices. Hopefully, this post has shown you that you can easily automate the process in R. So, whether you have a large collection of travel photos or just want to organize your everyday pictures, this could be an efficient way to do so. If you wish, you can even place the code in a function and add a few status messages to make it more reusable! (to reveal the code click on show code)\r\n\r\n\r\nShow code\r\n\r\nphoto_countries <- function(\r\n    path_orig, # path where pictures are located: \"example/\"\r\n    path_dest,   # path where pictures are to be copied to: e.g. \"example_sorted/\" \r\n    path_country_shapefile, # path to the shapefile containing country borders\r\n    plot_map = TRUE){ # Logical indicating whether to plot a map with all the picture locations (may be slow with many pictures)\r\n  \r\n  library(sf)\r\n  library(leaflet)\r\n  library(exifr)\r\n  \r\n  cat(paste0(\"\\rExtracting coordinates information from the picures\"))\r\n  \r\n  # extract info from all files\r\n  info <- read_exif(path = path_orig, tags = c(\"GPSLatitude\", \"GPSLongitude\", \"DateTimeOriginal\"), recursive = T)\r\n  \r\n  # plot photo location on map\r\n  if (plot_map){\r\n    leaflet(info) %>%\r\n      addTiles() %>%  \r\n      addCircleMarkers(lng= ~GPSLongitude, lat=~GPSLatitude, clusterOptions = markerClusterOptions())\r\n  }\r\n  \r\n  # load shapefiles countries\r\n  countries <- read_sf(path_country_shapefile)\r\n  \r\n  # just keep info on country name\r\n  countries <- countries[,c(\"NAME_LONG\",\"geometry\")]\r\n  \r\n  # info message\r\n  cat(paste0(\"\\rFinding countries for \", nrow(info), \" pictures\"))\r\n  \r\n  # convert info into vector points\r\n  points <- st_as_sf(info[!is.na(info$GPSLatitude),], coords = c(\"GPSLongitude\", \"GPSLatitude\"), crs = 4326)\r\n  \r\n  # intersect points with countries\r\n  countries_noegypt <- countries[-162,] #there seem to be issues with the shape of Egypt\r\n  country_match <- as.data.frame(st_intersects(points, countries_noegypt))\r\n  \r\n  # keep only first match if multiple\r\n  country_match <- country_match[!duplicated(country_match$row.id),]\r\n  \r\n  # add country name to table\r\n  info$country[!is.na(info$GPSLatitude)][country_match$row.id] <- countries_noegypt$NAME_LONG[country_match$col.id]\r\n  \r\n  # save info extracted\r\n  write.csv(info, \"info.csv\", row.names = FALSE)\r\n  \r\n  # make list of all countries \r\n  info$country <- ifelse(is.na(info$country), \"unknown country\", info$country)\r\n  countries_photos <- unique(info$country)\r\n  \r\n  # copy the pictures in the the destination directory\r\n  for (i in countries_photos){\r\n    \r\n    cat(paste0(\"\\rCopying pictures for country \", match(i, countries_photos), \"/\", length(countries_photos), \": \", i, paste0(rep(\" \",30), collapse = \"\")))\r\n    \r\n    # create a directory for each country for which there are pictures\r\n    if (!dir.exists(paste0(path_dest, i))){\r\n      dir.create(paste0(path_dest, i))\r\n    }\r\n    \r\n    # copy the picture in the destination directory\r\n    temp <- info[info$country == i, ]\r\n    file.copy(from= temp$SourceFile, to= paste0(path_dest, i), \r\n              overwrite = FALSE, recursive = FALSE, \r\n              copy.date = TRUE)\r\n    \r\n  }\r\n  \r\n  # message info\r\n  cat(paste0(\"\\rDONE! ;-)\\n\\n\"))\r\n  sort(table(info$country), decreasing = TRUE)\r\n  \r\n}\r\n\r\n\r\n\r\n\r\n\r\n",
    "preview": {},
    "last_modified": "2023-05-05T18:02:47+02:00",
    "input_file": "automatic-sorting-of-pictures-by-country.knit.md"
  },
  {
    "path": "posts/2022-12-20-what-to-visit-in-rome/",
    "title": "What to visit in Rome",
    "description": "I often get asked what to visit in Rome by friends and colleagues planning a trip. In this post I summarise my recommendations and share a few tips for the aspiring tourists.",
    "author": [
      {
        "name": "Francesco S. Bellelli",
        "url": {}
      }
    ],
    "date": "2022-12-20",
    "categories": [
      "other"
    ],
    "contents": "\r\n\r\nContents\r\nSome interesting facts\r\nThe most popular sites\r\nDay 1: Vatican\r\nSaint Peter basilica (San Pietro)\r\nVatican Museums (Musei Vaticani)\r\nSaint Angel Castle (Castel Sant’Angelo)\r\n\r\nDay 2: City centre\r\nPantheon\r\nNavona square (Piazza Navona)\r\nTrevi Fountain (Fontana di Trevi)\r\nCampo de’Fiori\r\nHigh streets of Rome\r\n\r\nDAY 3 ANCIENT ROME\r\nForum / Coliseum (Foro / Colosseo)\r\nCapitol (Campidoglio)\r\nAltare della patria\r\n\r\n\r\nOther important sites\r\nOther important churches\r\nMuseums\r\nOther famous sites\r\nPanoramic views\r\n\r\nTypical dishes from Rome\r\nPasta\r\nMeat\r\nVegetables / Sides\r\nStarters\r\n\r\nEating places\r\nIce cream (Gelato)\r\nRestaurants for typical dishes\r\nBest espresso in Rome (supposedly)\r\n\r\n\r\n\r\n\r\n\r\nFigure 1: Night view of Saint Peter’s cupolaSource: Julius Silver (Pexels)\r\n\r\n\r\n\r\nSome interesting facts\r\nLet’s start with a few interesting facts about Rome to stimulate your travelling appetite.\r\nThere are more ancient Egyptian obelisks standing in Rome than in the whole of Egypt. That’s mainly because the Roman emperor liked them a lot, so they brought a few back to the capital as souvenir.\r\nRome is also the city with the most fountains in the world. Most of them are pretty nice too.\r\nPerhaps unsurprisingly, Rome is also the city with the highest number of historical churches. You’ll see churches everywhere. And most of them are quite impressive and lavishly decorated on the inside. Also, Saint Peter basilica is one of the largest churches in the world.\r\nRome is nicknamed “the eternal city”. It is very old, according to legend, Rome was funded in 753BC, but there is evidence of older settlements.\r\nRome is also considered a romantic city. Obviously, the fact that the word ROMAntic comes from ROME plays a role. Also, in Latin if you read the name of ROMA backward, it spells AMOR, which means love.\r\nThe Vatican is the smallest country in the world (44 sq km). It is entirely enclosed within the city centre of Rome. Not many people know that there is a second piece of land which has extraterritorial status in Rome: it is the Sovereign Order of Malta’s headquarters. It’s a strange organization: It is not a country, but it can issue its own passports.\r\nThe most popular sites\r\nI don’t know why, but most of the travellers to Rome tend to book only three days. That is much less than what is actually needed to tour the city: you will be rushing around all day and still miss so many great things! I think at least five days are required, but since three days is the norm, I split the most famous attractions in three days (the ones every tourist goes to) and listed the other attractions, less touristic but equally nice, and which you will probably not have the time to visit, in the next section. For your reference, I added a map at the end of this section.\r\n\r\n\r\n\r\nFigure 2: The school of Athens (Raphael)\r\n\r\n\r\n\r\nDay 1: Vatican\r\nSaint Peter basilica (San Pietro)\r\nEntrance to the church is free, but expect very long queues (1h of wait is not uncommon)! Also, keep in mind that on Sundays there is a mass in the big square given by the pope, so I think you can’t visit inside in the morning. Around Christmas you’ll also see a big Christmas tree and nativity.\r\nYou can also climb to the top of the cupola, which is the highest building in Rome. This requires a ticket, but I highly recommend it if it is a nice day.\r\nVatican Museums (Musei Vaticani)\r\nInside you will find many famous artworks, including the Sistine chapel (Michelangelo) and school of Athens (Raffaello / Raphael). Again, the queue is super long! I advise you to buy the tickets online in advance so that you can skip the ticket office queue.\r\nSaint Angel Castle (Castel Sant’Angelo)\r\nThe castle of the Popes. It only served a couple of times for defence. In case of emergency the Pope can walk over the walls from its apartments (next to Saint Peter square) all the way to the castle. Oddly, the castle was built on top of Hadrian’s tomb, a Roman emperor. If you visit, you can see the different historical layers. Requires a ticket to visit.\r\n\r\n\r\n\r\nFigure 3: Fontana di TreviSource: Pexels\r\n\r\n\r\n\r\nDay 2: City centre\r\nPantheon\r\nAn architectural masterpiece built by the Romans. Still standing and currently used as church. Entrance is free. The dome was the largest in the world for thousand of years. If it looks familiar it’ because it inspired many buildings across the world.\r\nNavona square (Piazza Navona)\r\nThis is a very nice square. There are two famous fountains and around christmas it hosts Rome’s traditional Christmas market.\r\nTrevi Fountain (Fontana di Trevi)\r\nThe famous fountain where people throw coins. It’s usually very crowded! It’s also nice at night because of the lighting.\r\nCampo de’Fiori\r\nAnother nice square nearby.\r\nHigh streets of Rome\r\nThe triangle between Piazza del Popolo, Piazza Venezia and Piazza di Spagna is where most high street shops are located (Via del Corso and Via Condotti). I suggest you have a walk around and check the three squares I just mentioned. Also, when you go to Piazza del Popolo, make sure to climb up to the Pincio for a bit of a view.\r\n\r\n\r\n\r\nFigure 4: ColosseoSource: Riccardo Bertolo (Pexels)\r\n\r\n\r\n\r\nDAY 3 ANCIENT ROME\r\nForum / Coliseum (Foro / Colosseo)\r\nAgain, you will find long queues here. My advice is to buy the tickets at the entrance of the forum, because less people visit there but the ticket is the same (also, I recall the ticket is valid for 2 days).\r\nCapitol (Campidoglio)\r\nAccording to legend, the capitol hill is where Rome was founded. It has a special place in Roman history and it hosts the townhall of Rome since 1144 (obviously, this is where the name Washington’s capitol comes from). The square on top was designed by Michelangelo. On top of the hill there is also a nice church (Ara Cealis) and the Musei Capitolini. This is the oldest public museum in the world. It houses some famous Roman statues (e.g. Roman bronze statue of the she wolf feeding Romulus and Remus).\r\nAltare della patria\r\nYou won’t miss it, it’s the big white building next to the square Piazza Venezia with a large Italian flags on top. The building was built by Mussolini to celebrate soldiers who died in WWI. Piazza Venezia is also the place where Mussolini was giving public speeches.\r\n\r\n\r\n\r\nFigure 5: Main sites in RomeSource: Michelin green guide of Italy\r\n\r\n\r\n\r\nOther important sites\r\nHere is a list of a few more nice places in case you have time or happen to be close to it. Even with these, you would just be scratching the surface, there are a lot more places to visit in Rome. A common saying in Rome is that a lifetime would not be enough to view it all!\r\n\r\n\r\n\r\nFigure 6: Interiors of Basilica of Saint Paul Outside the WallsSource: Wikipedia\r\n\r\n\r\n\r\nOther important churches\r\nBasilica di San Giovanni (Sanctum sanctorum) - This is actually the real headquarters of the Roman Chatolic church. The obelisk in front of the church is the tallest in the world.\r\nBasilica di Santa Maria Maggiore\r\nChiesa cappuccini - This church has a crypt full of monk’s skulls (like the one in Paris)\r\nSanta Maria in Cosmedin (Bocca della verità)\r\nSan Luigi dei Francesi\r\nSanta Maria Trastevere\r\n\r\n\r\n\r\nFigure 7: Resting boxer, 2nd-3d century BC (Palazzo Massimo)Source: Wikipedia\r\n\r\n\r\n\r\nMuseums\r\nPalazzo Massimo, museo nazionale romano - I love this museum. It hosts the best Roman art I have ever seen. The mosaics are just unbelievable. If you have time, go! (it is usually less crowded than other sites)\r\nGalleria colonna\r\nPalazzo Barberini\r\nGalleria Borghese\r\nVilla Torlonia\r\n\r\n\r\n\r\nFigure 8: Cestius’ PyramidSource: Wikipedia\r\n\r\n\r\n\r\nOther famous sites\r\nQuirinale - the palace of the president. It is 30 times larger than the white house and a lot older and nicer inside! You can only visit with guided tours. Requires booking in advance.\r\nTerme di Caracalla - Ruins of an ancient bathhouse\r\nAra Pacis - Shrine to peace constructed by emperor Augustus. It’s beautifully preserved, very nice carvings. It’s normally not too crowded because it requires a ticket to enter. In my opinion it is worth a quick stop if you are nearby.\r\nVia Appia - Roman cobblestone road lined with ancient tombs. Good for hiking. Passes next to some an ancient Roman aqueduct.\r\nPiramide - A marble pyramid built by a Roman general. Just next to it, there is the protestant cemetery of Rome, where you can find the famous Angel of grief statue.\r\nCatacombs - underground network of tunnels used by Christian when they were persecuted by Roman emperors\r\nVilla Borghese - LArge park in the city centre of Rome. As the name suggests, It used to be part of the Borghese’s family villa. Now it’s public.\r\nEUR - Neighborhood built by Mussolini for the Olympic games (which finally never took place because of the war). It’s an interesting place to see the Fascist architectural style.\r\nDomus Aurea - Roman ruins of ancient empial palace\r\nCirco Massimo - Location where ancient romans used to organise charriot races. Not much is left, but the indentation in the ground is still visibile.\r\nPanoramic views\r\nGianicolo\r\nAventino / Villa del Priorato di Malta (famous keyhole view)\r\n\r\n\r\n\r\nFigure 9: Keyhole view from the Villa del Priorato di Malta Source: Wikipedia\r\n\r\n\r\n\r\nTypical dishes from Rome\r\nRome has many typical dishes. It’s culinary tradition comes from poor shepherds’ traditions, with abundant use of pork/lamb and less prestigious meat cuts. It’s a bit on the “heavy” side.\r\nPasta\r\nCarbonara - egg, cheese, pork, black pepper\r\nCacio e pepe - cheese and balck pepper\r\nAmatriciana - onion, tomato and pork\r\nGricia - lard and pork\r\nGnocchi alla romana - semolina gnocchi\r\nArrabbiata - tomato and chilli\r\nMeat\r\nPorchetta - roasted pork, usually served in sandwiches\r\nCoda alla vaccinara - oxtail stew\r\nSaltimbocca alla Romana - veal + slice of ham + sage\r\nAbbacchio scottadito - roasted lamb chops\r\nCoratella / pajata - stews made of assorted lamb innards\r\nPollo ai peperoni alla romana - chicken with bell peppers\r\nTrippa alla romana - tripe\r\nVegetables / Sides\r\nCarciofi alla romana / carciofi alla giudea - artichokle\r\nPuntarelle / cicoria alla romana - Greens, usually cooked with garlic and chilli\r\nZucchine romanesche - A type of courgette common in Rome, sweeter with lighter colour\r\nBroccoli romaneschi - roman broccoli\r\nStarters\r\nSuppli - fried rice ball with cheese\r\nFiori di zucca - Fried courgette flowers filled with anchovies and cheese\r\n\r\n\r\n\r\nFigure 10: Restaurant in the city centreSource: Fineas Anton (Pexels)\r\n\r\n\r\n\r\nEating places\r\nI am not very good because I have been away for a while, but here a few I can recommend:\r\nIce cream (Gelato)\r\nOld Bridge - small shop just next to the vatican. You often see nuns and priest queuing up\r\nGiolitti - in the city centre\r\nVenchi - many shops across the city\r\nRestaurants for typical dishes\r\nThese are popular places, they will require booking in advance\r\nLuciano cucina italiana, Sora Lella, Armando al Pantheon, Osteria al Grappolo d’oro, Osteria della trippa, Poldo e Gianna.\r\nBest espresso in Rome (supposedly)\r\nCaffè Sant’Eustachio\r\n\r\n\r\n\r\n",
    "preview": "posts/2022-12-20-what-to-visit-in-rome/cupolone.jpg",
    "last_modified": "2023-05-02T10:23:28+02:00",
    "input_file": "what-to-visit-in-rome.knit.md"
  },
  {
    "path": "posts/2022-08-07-updates-to-package-countries/",
    "title": "Updates to package countries",
    "description": "Version 0.2 of package countries is out. This article is a short description of some of the new functions.",
    "author": [
      {
        "name": "Francesco S. Bellelli",
        "url": {}
      }
    ],
    "date": "2022-08-07",
    "categories": [
      "coding"
    ],
    "contents": "\r\n\r\nContents\r\nFirst, let’s install the latest version of the package\r\nThen let’s load an example dataset\r\nFinding columns containing country and time information\r\nTesting dates\r\nFinding table keys\r\nTweaked which.min and which.max functions and statistical mode\r\nWhat will come next?\r\n\r\nThe version 0.2 of the package introduces several functions that identify special columns in country data. These functions can be used as building blocks to automate basic tasks and detect data formats. Here is an overview of a the new functionalities.\r\nFirst, let’s install the latest version of the package\r\n\r\n\r\n# Install and load devtools if needed\r\ninstall.packages(\"devtools\")\r\nlibrary(devtools)\r\n\r\n# Install and load countries package\r\ndevtools::install_github(\"fbellelli/countries\", build_vignettes = TRUE)\r\n\r\n\r\n\r\n\r\n\r\n#load the package\r\nlibrary(countries)\r\n\r\n\r\n\r\nThen let’s load an example dataset\r\nIn this article we will use a dataset of country policies as an example for the functions in the package. This dataset contains 41 columns and has a rather complex strutcture. Every row is identified by a combination of Country name (column 21), Year (Column 9), Policy measure number (column 1), and HS code (column 39) — which is a code identifying traded commodities. This dataset is an extension based on the WTO environmental databse (EDB). More information on the dataset can be found here.\r\n\r\n\r\n#download data\r\ntemp <- tempfile()\r\ndownload.file(\"https://fbellelli.com/data%20files/Extended%20EDB%20by%20measure-country-HS%20chapter.zip\", temp, mode=\"wb\")\r\n\r\n#unzip and load it in R\r\nexample <- read.csv(\r\n  unzip(temp,\"Extended EDB by measure-country-HS chapter/Extended EDB (by measure-country-HS chapter).csv\"),\r\n  stringsAsFactors=FALSE)\r\n\r\n\r\n\r\nFinding columns containing country and time information\r\nThe functions find_countrycol() and find_timecol() can be used to return respectively all columns containing country names and date/year information.\r\nIn the example below, the function find_countrycol() is used to examine our example dataset. The argument min_share is used to indicate whether to look for an entire column of Country names or any column that contains Country names. This is a numeric value indicating the minimum share of entries in the column that are country names.\r\n\r\n\r\n#Columns of country names\r\nfind_countrycol(example)  \r\n\r\n\r\n[1] \"COUNTRIES\"\r\n\r\n#Return any column containing a country name\r\nfind_countrycol(example, min_share=0) \r\n\r\n\r\n[1] \"Notifying.Member\" \"COUNTRIES\"       \r\n\r\nSimilarly, we can look for time columns in the following way:\r\n\r\n\r\n# Date and year columns\r\nfind_timecol(example)  \r\n\r\n\r\n[1] \"Year\"\r\n\r\nBy default, the function will return the name of the column. However, the argument return_index can be used to get the indices of the column in the table.\r\n\r\n\r\nfind_countrycol(example, return_index = TRUE)\r\n\r\n\r\n[1] 21\r\n\r\nfind_timecol(example, return_index = TRUE)  \r\n\r\n\r\n[1] 9\r\n\r\nComputations may take long on large tables with many columns. To speed up operations, these functions operate by evaluating the table on a random sample of rows. The sample size can be adjusted with the argument sample_size. It also possible to request to use the entire table by passing the value NA. Finally, it is also possible to request not to return columns containing NA values by specifying: allow_NA = FALSE.\r\nThese two functions are based on is_country() and is_date(), which can be used to test if a string is a Country name and a date. An overview of the first function is provided in the vignette Dealing with country names, here we have a look at `is_date()´.\r\nTesting dates\r\nis_date() takes a string vector as argument and outputs a boolean vector indicating whether the strings are dates. The argument formats can be used to specify the formats to be checked. Standard R notation can be used for date elements (see the table below).\r\n\r\n\r\ntest <- c(\"December 2022\", \"20/01/1970\", \"Banana\", \"12.13.2000\") \r\n\r\nis_date(test)\r\n\r\n\r\n[1]  TRUE  TRUE FALSE  TRUE\r\n\r\n\r\nSymbol\r\nDefinition\r\nExample\r\n%d\r\nDay number\r\n13\r\n%a\r\nAbbreviated day name\r\nMon\r\n%A\r\nFull day name\r\nMonday\r\n%m\r\nMonth number\r\n2\r\n%b\r\nAbbreviated month name\r\nFeb\r\n%B\r\nFull month name\r\nFebruary\r\n%y\r\nYear 2-digits\r\n22\r\n%Y\r\nYear 4-digits\r\n2022\r\n\r\nFinding table keys\r\nfind_keycol() is a function that can be used to automate the search of key columns in datasets. A table key is a column or set of columns that uniquely identifies the entries in the table. This function was specifically designed for country data, so it will prioritise the search of country and time columns, which are often keys in country data.\r\nAs shown below, the function correctly identifies the keys for the complex dataset introduced at the beginning of this article.\r\n\r\n\r\nfind_keycol(example, allow_NA = TRUE)\r\n\r\n\r\n                      country                          time \r\n                  \"COUNTRIES\"                        \"Year\" \r\n                        other                         other \r\n                         \"Nr\" \"Tentative.HS.chapters.match\" \r\n\r\nThe function outputs a vector of column names that uniquely identifies the entries in the table. In addition, it also indicates whether the column contains country, time or other information. Just like the other find function in this page, it is possible to request the column index instead of the name by passing return_index = TRUE.\r\nDue to the potentially very high number of column combinations in a table, the function only tests the more likely options. The function will first check country and time columns. Next, left-most columns are prioritised. Also, the function will only look for the most common country data formats (e.g. cross-sectional, time-series, panel data, dyadic, etc.) and only searches for up to two additional key columns of type other. If no key is found at the end of the search, the function returns a NULL value.\r\nComputation can be slow on large datasets. Therfore, the function relies on a sample of row. The sample size can be controlled with sample_size. Moreover, it is also possible to restrict the search to a subset of columns by providing a vector of column names or indices in the argument search_only.\r\n\r\n\r\n#This will only check if a key is found among the first three columns\r\nfind_keycol(example, allow_NA = TRUE, search_only = 1:3)\r\n\r\n\r\nNULL\r\n\r\nFinally, the function also permits the user to specify whether columns containing NA values are allowed to be considered as table keys. The default is allow_NA = FALSE because keys should typically not contain missing values. However, in our example dataset the column Tentative.HS.chapters.match contains blank entries which are read in R as NA, therefore the default would return NULL. The argument allow_NA is present to deal with these edge cases.\r\n\r\n\r\nfind_keycol(example, allow_NA = FALSE)\r\n\r\n\r\nNULL\r\n\r\nIf the user wants to test a specific set of columns, the package also provides the function is_keycol() to check whether the provided columns uniquely identify the entries in the dataset.\r\n\r\n\r\nis_keycol(example, c(\"COUNTRIES\",\"Year\"), allow_NA = TRUE)\r\n\r\n\r\n[1] FALSE\r\n\r\nis_keycol(example, c(\"COUNTRIES\",\"Year\", \"Nr\",\"Tentative.HS.chapters.match\"), allow_NA = TRUE)\r\n\r\n\r\n[1] TRUE\r\n\r\nTweaked which.min and which.max functions and statistical mode\r\nVersion 0.2 also introduces the which_min, which_max and which_mode. These functions return the position (index) respectively of the minimum, maximum, and mode values of the vector. Unlike base R functions which.min and which.max, these functions return the position of ALL minima/maxima instead of only the first one. If desired, one can request only the first value with the argument first_only. Here is an example:\r\n\r\n\r\n# Return position of all minimum values. Example: Return position of measures with the lowest score?  \r\nwhich_min(example$MEASURE_SCORE)\r\n\r\n\r\n[1] 82520 82521\r\n\r\n# Compare this with which.min, which will return only the first value:\r\nwhich.min(example$MEASURE_SCORE)\r\n\r\n\r\n[1] 82520\r\n\r\n# If desired, the same behaviour can be obtained with the argument \"first_only\"\r\nwhich_min(example$MEASURE_SCORE, first_only = TRUE)\r\n\r\n\r\n[1] 82520\r\n\r\nThe package also provide a function to get the mode of a vector. That is to say, the observation that appear most frequently in a vector. It supports both numeric, factor and character variables. In case of\r\n\r\n\r\n#return the mode of a vector. Example: which country has the most measures in the dataset? United States\r\ncountries::mode(example$COUNTRIES)\r\n\r\n\r\n[1] \"United States\"\r\n\r\n#if multiple modes are present, all of them will be returned, unless only the first is requested:\r\ncountries::mode(c(1,1,2,3,3,4))\r\n\r\n\r\n[1] 1 3\r\n\r\ncountries::mode(c(1,1,2,3,3,4), first_only=TRUE)\r\n\r\n\r\n[1] 1\r\n\r\n#we can also get the position of all US entries\r\nhead(which_mode(example$COUNTRIES),10)\r\n\r\n\r\n [1] 1093 1094 1098 1099 1100 1112 1115 1116 1120 1121\r\n\r\nWhat will come next?\r\nThis version of the package introduces many building blocks that will be used to design more advanced functionalities.\r\nThe next package version will aim to bring a merging function that deals with differences in country names and with time columns. I will also work on a wrapper function to allow easy download of country data from public sources (e.g. World Bank, IMF, FRED, etc…). Ideally, we want to be able to download country data from multiple sources and obtain a single table with merged data ready to use, all in one simple command.\r\n\r\n\r\n\r\n",
    "preview": "posts/2022-08-07-updates-to-package-countries/../../images/Countries_logo.png",
    "last_modified": "2022-08-09T12:19:53+02:00",
    "input_file": {},
    "preview_width": 864,
    "preview_height": 1000
  },
  {
    "path": "posts/2022-05-22-a-brief-introduction-to-natural-hazard-risk-analysis/",
    "title": "A brief introduction to natural hazard risk analysis",
    "description": "This article is a quick guide on the basic steps involved in natural hazard risk analysis. It briefly touches on some of the most common steps:  geocoding, hazard maps, damage curves and climate projections. I demonstrate how R can be used to assess exposure of assets with a simple example on flood risk for presidential palaces around the world.",
    "author": [
      {
        "name": "Francesco S. Bellelli",
        "url": {
          "https://fbellelli.com/": {}
        }
      }
    ],
    "date": "2022-05-22",
    "categories": [
      "risk",
      "coding",
      "environment",
      "other"
    ],
    "contents": "\r\n\r\nContents\r\nFirst things first\r\nGeocoding\r\nHow to find out information on flood risk\r\nLoading hazard maps\r\nA brief note on coordinate systems\r\n\r\nExtracting flood risk information\r\nIntersecting asset location with hazard maps\r\nExtracting flood depth for multiple return periods\r\nExpected flooding levels\r\n\r\nConverting hazard distributions into expected damages\r\nDamage curves\r\nCalculating expected damages\r\n\r\nClimate change: the elephant in the room\r\n\r\n\r\n\r\n\r\nFirst things first\r\nThe fundamental prerequisite for any risk exposure assessment is to have a list of assets for which we wish to conduct the analysis. As an illustrative purpose, we can imagine we have been tasked to analyse flood risk for presidential palaces around the world. This Wikipedia page provides a list of palaces names with the name of the city and country in which they are located. I extracted, cleaned and saved the information of 143 presidential palaces in a csv file, which can be downloaded here to follow along with the example.\r\n\r\n\r\n#load list of palaces\r\npalaces <- read.csv(\"presidential_palaces_geocoded_with_risk.csv\", encoding=\"UTF-8\")\r\n\r\n\r\n\r\nGeocoding\r\nOnce we have a collection of asset, the first step is to convert addresses into latitude and longitude coordinates — this operation is known as geocoding. Geocoding is important because it gives geographic coordinates that are easily interpretable by a computer. This will allow to place our assets on a map and extract information on flood risks.\r\nGeocoding is usually performed with an API (e.g. Google maps, OpenStreetMap, …) that takes in addresses and spits out coordinates. Nowadays, these APIs require the user to provide keys in order to limit the number of requests. Here is a list of the most common packages for doing this in R:\r\nggmap\r\nnominatimlite\r\nosmdata\r\ntidygeocoder\r\nAttentive readers, might have noticed that we already provided longitude and latitudes in the example file. We got these coordinates with the following code.\r\n\r\n\r\nlibrary(ggmap)\r\n\r\n# insert personal google API key - this requires registration \r\nregister_google(key=\"WRITE YOUR KEY HERE\")\r\n\r\n#geocode addresses\r\ngeo <- geocode(paste0(palaces$Building,\", \",palaces$Country))\r\n\r\n#import geocodes in table\r\npalaces <- cbind(palaces,geo)\r\n\r\n\r\n\r\nNow that we have the coordinates of the palaces, we can easily place them on an interactive map with the package leaflet. The names of the palaces can be visualised by hovering over the markers.\r\n\r\n\r\nlibrary(leaflet)\r\n\r\nleaflet(palaces) %>%\r\n  addTiles() %>%  \r\n  addMarkers(lng= ~ lon, lat= ~ lat, label= ~ Building)\r\n\r\n\r\n\r\n\r\nHow to find out information on flood risk\r\nThe goal of our analysis is to obtain information on the risk exposure of different assets. The easiest way to get it, is to refer to hazard maps. Hazard maps are maps which identify areas that are vulnerable to a particular hazard. They are built by experts based on geophysical modelling that incorporate all the main factors affecting hazard exposure. Many government agency across the world build hazard maps to manage risk in their countries. For instance, in the Unites States, the reference flood hazard map is the one from the Federal Emergency Management Agency (FEMA).\r\nLoading hazard maps\r\nIn this example, we will use the riverine flood maps from Acqueduct, which have a resolution of 30 arc second (roughly 1km at the equator). Although higher granularity may be advisable for flood assessment, Acqueduct maps have the advantages of being publicly available, having a global coverage and having projections under different climate scenarios.\r\nAcqueduct flood maps are available for different return periods (2, 5, 10, 25, …, 1000 years). Return periods are the inverse of probabilities. For instance, a 1 in 100 year flood is a flood of such intensity that it will be equalled or exceeded on average once every 100 years, i.e. a flood which has a 1% probability of occurring in a given year.\r\nFor each return period, Aqueduct’s flood map display the expected inundation depth (in meters). In other words, Aqueduct provides a set of flood map which give slices of the probability-depth joint distribution. The beautiful figure below illustrates how these maps look like. Lighter colours indicate inundated areas in the event of a 1 in 500 years flood. Understandibly, the map shows that areas around rivers are at higher risk of riverine floods and quantifies the severity of this risk in term of inundation depth.\r\n\r\n\r\n\r\nFigure 1: Aqueduct riverine historical flood map - 500 year return period\r\n\r\n\r\n\r\nAcqueduct flood maps come as raster files (.tif), in which each pixel encodes the expected inundation depth. We can use the package terra to work with this type of data in R. Let’s load the map with the following command\r\n\r\n\r\nlibrary(terra)\r\n\r\n#path to Aqueduct hazard map - riverine flooding (100 years return period) \r\nmap_path <- \"http://wri-projects.s3.amazonaws.com/AqueductFloodTool/download/v2/inunriver_historical_000000000WATCH_1980_rp00100.tif\"\r\n\r\n#load hazard map in R\r\nrflood100 <- terra::rast(map_path)\r\n\r\n\r\n\r\nNotice that vector data (e.g. .shp, GeoJSON) are also a common formats for hazard maps. In vector formats the information is attached to polygons instead of pixels. For manipulating vector spatial data, the package sf is my favourite alternative. Vector data can be loaded with the functions sf::read_sf() or terra::vect(). Vector spatial data could be the subject of another post.\r\nA brief note on coordinate systems\r\nSpatial data often comes with information on the underlying coordinate system and map projections. Computers programmes will often be able to read these information and automatically convert it as needed. However, it might occasionally be necessary to specify manually this information. For example, if we wish to indicate that our lat and long columns correspond to the latitude and longitude commonly used in the real world by GPS systems or to perform changes of coordinates for mapping.\r\nTherefire, it might be useful to know that latitude and longitude of points of assets and polygons are very often expressed in the World Geodesic System of 1984 (WGS84) and that rasterised maps normally use an equirectangular projection because this projections maps the surface of the earth onto a grid, thus it can be easily linked to the pixels of an image.\r\nThat being said, this topic is way to vast to fit in this article and my limited knowledge would not do justice to this fascinating corpus of scientific work. The issues associated with coordinate system, projections and their distortions kept bright human minds busy for centuries. I highly recommend this series of articles from the Australian and New Zealand Spatial Information Council for a wonderfully written introduction on all these mapping topics.\r\nExtracting flood risk information\r\nNow that we have hazard maps with flood risk information and geocoded asset locations, all that is left to do is to extract information for our locations of interest.\r\nIntersecting asset location with hazard maps\r\nWe can use the same package, terra, to perform this operation with one line of code. First, we declare the columns lon and lat as coordinates for the palaces position. Then, we use the function extract to extract information from the flood map for our list of presidential palaces. Finally, we save the results in the palaces table.\r\n\r\n\r\n#convert palaces into vector points\r\npalaces_vect <- terra::vect(palaces, geom=c(\"lon\",\"lat\"))\r\n\r\n#extract information for palaces\r\ntemp <- terra::extract(rflood100, palaces_vect) \r\n\r\n#save extracted information in palaces table\r\npalaces$flood <- temp[,2]\r\n\r\n\r\n\r\nCitizens around the world will be pleased to hear that most palaces around the world are not at risk of getting flooded. In the following table we list the top ten palaces in which leaders are most likely to get their feet wet in case of a 1 in a 100 year flood. Only three palaces have a flooding depth higher than 1m, which could be considered as an extreme flood.\r\n\r\nTable 1: Ten worst flooded palaces in case of a 1 in 100 year flood\r\nCountry\r\nBuilding\r\nFlood depth (m)\r\nGabon\r\nPresidential Palace, Libreville\r\n3.4\r\nSudan\r\nPresidential Palace, Khartoum\r\n2.4\r\nGermany\r\nVilla Hammerschmidt, Bonn\r\n2.3\r\nTunisia\r\nCarthage Palace, Tunis\r\n0.9\r\nPhilippines\r\nMalacañang Palace, Manila\r\n0.5\r\nSomalia\r\nVilla Somalia, Mogadishu\r\n0.3\r\nKazakhstan\r\nAk Orda Presidential Palace, Nur-Sultan\r\n0.3\r\nGermany\r\nBellevue Palace, Berlin\r\n0.2\r\nEast Timor\r\nNicolau Lobato Presidential Palace, Dili\r\n0.1\r\nDjibouti\r\nPresidential Palace, Djibouti City\r\n0.1\r\n\r\nExtracting flood depth for multiple return periods\r\nNow that we know how information can be extracted, we can repeat the procedure for different return periods so as to have a complete picture of the distribution for different flood severity. This is time-consuming step, hence, I already included the results in the example data.\r\n\r\n\r\n#convert palaces into vector points\r\npalaces_vect <- terra::vect(palaces, geom=c(\"lon\",\"lat\"))\r\n\r\n#loop over all return periods\r\nfor (i in c(\"0002\",\"0005\",\"0010\",\"0025\",\"0050\",\"0100\",\"0250\",\"0500\",\"1000\")){\r\n  \r\n  # prepare path to hazard map\r\n  map_path <- paste0(\"http://wri-projects.s3.amazonaws.com/AqueductFloodTool/download/v2/inunriver_historical_000000000WATCH_1980_rp0\",i,\".tif\")\r\n\r\n  #load map  \r\n  flood <- terra::rast(map_path)\r\n  \r\n  #extract information\r\n  temp <- terra::extract(flood, palaces_vect)\r\n  \r\n  #save information in palaces table\r\n  palaces[,paste0(\"flood\",i)] <- temp[,2]\r\n}\r\n\r\n\r\n\r\nHaving the full distribution of probability-depth of flooding allows to make some interesting comparisons. The next graph shows the risk profile of the three properties with the highest flooding risk.\r\nWe can see that Villa Hammerschmidt (Bonn) has 10% (1/10 yr) probability of having a 1 meter flood, while the presidential palaces in Karthoum has around 3% (1/33 yr) of experiencing a flood with similar depth levels.\r\nOverall, it appears that Villa Hammerschmidt (Bonn) is more likely to get flooded regularly, while the presidential palace in Karthoum has lower flood probabilities, but it has higher expected flood depth in case of extreme floods (1 in 100 year or higher). Finally the presidential palace in Libreville has higher expected flooding levels for all return periods.\r\n\r\n\r\n\r\nFigure 2: Probability-depth distribution for the three most exposed palaces\r\n\r\n\r\n\r\nExpected flooding levels\r\nHaving the full probability-severity distribution allows for a greater richness of details. However, sometimes it is handy to have a single metric that encapsulates the risk profile of an asset. To do this, we can calculate the annualised expected flood level by summing over the flood depths weighted by their probabilities (inverse of return period). One important thing to keep in mind when aggregating multiple return periods is that flood maps provide the exceedance probability corresponding to flood levels. For instance, if the 100yr flood map indicates 1m flooding for a property, then it means that there is a 1% probability of flooding with a depth of at least 1m. In the figure below, I drew the exceedance curve for the top 3 properties at risk. This curve depicts the flood distribution of the properties and it is constructed by plotting the flood depth associated with each exceedance probability (\\(1/Return\\;period\\)).\r\n\r\n\r\n\r\nFigure 3: Non-exceedance curve for the three most exposed palaces\r\n\r\n\r\n\r\nThen, we can approximate the expected flood level by computing the area under the exceedance curve, which can be interpreted as a probability-weighted sum of all flood depths. We do not observe the full curve, but ony a few scattered points corresponding to the return period maps. So, for the purpose of the expected value calculations, we will assume that the curve is linear between the observed points, this will facilitate calculations and should be more realistic than a stepwise function. From the formula of trapezoid’s area, the area under the curve can be written as:\r\n\\[ \r\nE[\\text{Flooding}]_i = \\sum^{n-1}_{j=1}\\frac{1}{2}\\left(\\frac{1}{RP_{j}} + \\frac{1}{RP_{j+1}}\\right)\\cdot \\left(Depth_{i,j+1} - Depth_{i,j}\\right) \r\n\\]\r\nWhere, \\(i\\) is an index for the asset and \\(j\\) an index for the \\(n\\) available return periods. So that \\(RP_{j}\\) indicates the return period associated with the \\(j\\)-th index and \\(Depth_{ij}\\) indicates the depth level expected for asset \\(i\\) with return period \\(RP_{j}\\). We can implement this calculation in R by using the dplyrand tidyrpackages.\r\n\r\n\r\nlibrary(dplyr)\r\nlibrary(tidyr)\r\n\r\n#tidying up the table into a long format (this facilitates calculations in R)\r\nlong_table <- palaces %>%\r\n  pivot_longer(cols=starts_with(\"flood\"),\r\n               names_to = \"return_period\",\r\n               values_to = \"flood_depth\") %>%\r\n  mutate(return_period = as.numeric(substr(return_period, 6,10)))\r\n\r\n#calculating the expected flood level\r\nrisk_table <- long_table %>%\r\n  mutate(prob_exceedance = 1/return_period) %>%\r\n  group_by(Building) %>%\r\n  arrange(return_period) %>%\r\n  summarise(expected_flood = sum(ifelse(return_period == max(return_period), \r\n                                    0, \r\n                                    0.5*(prob_exceedance + lead(prob_exceedance))*(lead(flood_depth)-flood_depth))), .groups=\"drop\")\r\n\r\n\r\n\r\nWe can then rank the palaces according to this metric. We find that the Presidential palace in Libreville and the Villa Hammerschmidt (Bonn) are the palaces at greater risk of riverine flooding in our sample. It is plausible that these palaces are at high flood risk, the presidential palace in Libreville is located just next to the sea, and villa Hammerschmidt is built on the shores of the Rhine, as shown in the map below. However, the depth levels seems suspiciously high, it would be advisable to use alternative maps (possibly with higher granularity) to double-check these numbers. Perhaps the map used here do not take into account flood defences that were built to prevent regular flooding.\r\n\r\nTable 2: The ten palaces at highest flooding risk\r\nBulding\r\nAnnualised expected flood level (cm)\r\nPresidential Palace, Libreville\r\n48\r\nVilla Hammerschmidt, Bonn\r\n35\r\nPresidential Palace, Khartoum\r\n10\r\nCarthage Palace, Tunis\r\n9\r\nVilla Somalia, Mogadishu\r\n5\r\nAk Orda Presidential Palace, Nur-Sultan\r\n5\r\nMalacañang Palace, Manila\r\n4\r\nBellevue Palace, Berlin\r\n3\r\nNicolau Lobato Presidential Palace, Dili\r\n2\r\nPresidential Palace, Djibouti City\r\n2\r\n\r\n\r\n\r\n\r\nConverting hazard distributions into expected damages\r\nSo far, the analysis has concentrated on quantifying the exposure to physical risks. Next, we might want to convert this exposure into expected damages to our assets. Damage curves are the standard tool applied to achieve this.\r\nDamage curves\r\nDamage curves, also vulnerability functions, are curves mapping the intensity of an hazard to the expected damage to an asset, which is typically expressed as a damage ratio — i.e. percentage of asset construction value that is lost. These curves are usually estimated from historical damage data.\r\nThe actual damage incurred by an asset will depend on a multitude of factors. For example, in the case of a riverine flood, we can immagine that the presence of basement, the height of the house floor, number of floors, materials, construction methods, whether preventive measure have been taken, etc., are all factors that will modify the impact of flooding on the property.\r\nTherefore, there is no there is no universal damage curve that can be applied to all types of assets. Usually, different damage curves are devised according to key characteristics of the assets, such as material, construction techniques, positioning, orientation, shape, height, layout, number of windows, etc. This will allow to get a more accurate estimate of the effective hazard damages.\r\nNevertheless, for the sake of this example, let’s keep things simple and assume a unique damage curve is representative for all presidential palaces. We will take an average damage curves without worrying too much about construction specifications. In the figure below, I plotted average damages curves developed in this research paper of the JRC (European Commission) for different regions of the World. If you wish to download the curves used in this example, a cleaned version of the data is availablehere.\r\n\r\n\r\n\r\n\r\n\r\n\r\nFrom the figure, it can be seen that on average building in Central and South America are more vulnerable than buildings in Asia. For the same inundation levels (x-axis), a higher damage ratio is expected (y-axis).\r\nIn order to keep things simple, this example will only keep the European damage curve and apply it to all presidential palaces, irrespectively of their location. This choice is completely arbitrary. I chose to keep the European curve because it is the one which associates the lowest expected damages to floods. This selection is based on the criterion that presidential palaces are likely to be built with high specifications and usually undergo constant checks and maintenance. In any case, the purpose of this example is to illustrate to general process rather giving exact damage figures.\r\n\r\n\r\n#load list of palaces\r\ndamage_curve <- read.csv(\"flood_damage_curve_residential_buildings.csv\")\r\n\r\n#Keep only the European curve and rename it\r\ndamage_curve <- damage_curve[,c(\"FloodDepth\",\"Europe\")]\r\ncolnames(damage_curve)[2] <- \"DamageRatio\"\r\n\r\n\r\n\r\nCalculating expected damages\r\nThe original damage curves in the JRC paper are defined by 9 flood depth points (0, 0.5, 1, …, 6). In order to get estimates for intermediate values (e.g. 0.3m of flooding) we can interpolate the damage ratios between these points. With the following code, I build a table that summarises the damage curve with a bit more granularity.\r\n\r\n\r\ninterpolated_damage_curve <- data.frame(FloodDepth=seq(0,6,0.1))\r\ninterpolated_damage_curve <- left_join(interpolated_damage_curve, damage_curve, by=\"FloodDepth\")\r\n\r\nlibrary(zoo)\r\ninterpolated_damage_curve <- interpolated_damage_curve %>%\r\n  zoo(.)%>%\r\n  apply(., MARGIN = 2, FUN = zoo::na.approx) %>%\r\n  as.data.frame()\r\n\r\n\r\n\r\nNow that we have a nice summary table, we can easily import the expected damage ratio for each presidential palaces by matching the expected flooding level under different return periods with the ones in the interpolated damage curve table.\r\n\r\n\r\n#In the data frame long table, each entry correspond to an asset-return period combination\r\n\r\n#merging is done on the rounded expected flood depth (converted to character to facilitate merging and avoid problems associated with floating point numbers)\r\nlong_table$rounded_flood_depth <- as.character(round(long_table$flood_depth,1))\r\ninterpolated_damage_curve$FloodDepth <- as.character(interpolated_damage_curve$FloodDepth)\r\nlong_table <- dplyr::left_join(long_table,interpolated_damage_curve,by=c(\"rounded_flood_depth\"=\"FloodDepth\"))\r\n\r\n\r\n\r\nThen, we can proceed to calculating the expected damage ratio for the presidential palaces by taking a weighted average of the damage ratios over each return period.\r\n\\[ \r\nE[\\text{Flooding}]_i = \\sum^{n-1}_{j=1}\\frac{1}{2}\\left(\\frac{1}{RP_{j}} + \\frac{1}{RP_{j+1}}\\right)\\cdot \\left[D_i(Depth_{i,j+1}) - D_i(Depth_{i,j})\\right] \r\n\\]\r\nThis formula is nearly identical to the one used for the average flood level, the only addition is the function \\(D_{i}\\), which transforms the input — flood depth — into a damage ratio based on the vulnerability curve for the property. We can easily calculate this in R as follows:\r\n\r\n\r\n#calculating the expected flood level\r\ndamage_table <- long_table %>%\r\n  mutate(prob_exceedance = 1/return_period) %>%\r\n  group_by(Building) %>%\r\n  arrange(return_period) %>%\r\n  summarise(expected_flood_damage = sum(ifelse(return_period == max(return_period), \r\n                                    0, \r\n                                    0.5*(prob_exceedance + lead(prob_exceedance))*(lead(DamageRatio)-DamageRatio))), .groups=\"drop\")\r\n\r\n\r\n\r\nThe table below lists the palaces that have the highest expected flood damage. As we already mentioned before, the results for the first two palaces seems suspiciously high — if the 15.7% expected annual damage from flood were an accurate figure, fisheries would be a more fitting allocation of the grounds of Gabon’s Presidential palaces. It would be advisable to use alternative maps (possibly with higher granularity) to double-check these numbers. Also, there might be preventive measures in place that the maps do not take into account (e.g. embankments) that can explain this result.\r\n\r\n\r\ndamage_table %>% \r\n  arrange(desc(expected_flood_damage))%>%\r\n  head(10) %>%\r\n  mutate(expected_flood_damage=100*expected_flood_damage)%>%\r\n  knitr::kable(., \r\n               caption=\"The ten palaces with the highest expected flooding damages\",\r\n               align=c(\"l\",\"c\"),\r\n               col.names=c(\"Palace\", \"Annualised expected damage (%)\"),\r\n               digits=1)\r\n\r\n\r\nTable 3: The ten palaces with the highest expected flooding damages\r\nPalace\r\nAnnualised expected damage (%)\r\nPresidential Palace, Libreville\r\n15.7\r\nVilla Hammerschmidt, Bonn\r\n12.9\r\nCarthage Palace, Tunis\r\n3.9\r\nPresidential Palace, Khartoum\r\n3.1\r\nVilla Somalia, Mogadishu\r\n2.7\r\nAk Orda Presidential Palace, Nur-Sultan\r\n2.3\r\nBellevue Palace, Berlin\r\n1.9\r\nMalacañang Palace, Manila\r\n1.7\r\nNicolau Lobato Presidential Palace, Dili\r\n0.8\r\nPresidential Palace, Djibouti City\r\n0.8\r\n\r\nClimate change: the elephant in the room\r\nThe entire analysis we conducted to this point ignores once crucial element: climate change. Because of it, extreme weather patterns are predicted to become more frequent and intense in most places around the globe. Hence, risk analyses should take this into account.\r\nMost hazard maps are based on historical data — they are backward looking by construction. The problem is that past occurrences might not be representative of future risk if the underlying climate is changing. The solution is using maps that incorporate the changes in risk due to climate change patterns. Climate models are used to predict how extreme weather events will change in the future under different emission scenarios.\r\nThe problem of these climate models is that they have inherent uncertainty in predicting complex system over long horizon. Therefore, estimates may come with large uncertainty bands and vary between models. Moreover, Many of these models have low spatial granularity, therefore results may be too coarse to be translated into risk maps. Nevertheless, there is much research going on in this area and our understanding and tools will certainly get better in the near future.\r\nI would like to mention that the Acqueduct flood maps are available also under two different climate scenarios (RCP4.5 and RCP8.5) with prediction from four different climate models. Dear reader, a perfect exercise to test your understanding would be to replicate this analysis with one of the hazard maps under the RCP8.5 scenario (corresponding to a pessimistic, business as usual concentration pathway) and compare the results to the ones obtained here with historic data. How do results change for our list of presidential palaces? You should find an increase in flood risk and expected flood damages.\r\n\r\n\r\n\r\n",
    "preview": "posts/2022-05-22-a-brief-introduction-to-natural-hazard-risk-analysis/flood.jpg",
    "last_modified": "2022-07-19T11:00:17+02:00",
    "input_file": {}
  },
  {
    "path": "posts/2022-02-27-first-version-of-countries/",
    "title": "First version of countries",
    "description": "The first development version of the package countries is now available on Github. This post looks at how the package can be used to work with country names.",
    "author": [
      {
        "name": "Francesco S. Bellelli",
        "url": {}
      }
    ],
    "date": "2022-02-27",
    "categories": [
      "coding"
    ],
    "contents": "\r\n\r\nContents\r\nInstalling and loading the package\r\nDealing with country names\r\nFurther options and warning messages\r\nUsing custom conversion tables\r\nWork in progress\r\n\r\n\r\n\r\n\r\n\r\ncountries is an R package designed to quickly wrangle, merge and explore country data. This package will contain functions to easily identify and convert country names, pull country info and datasets, merge country data from different sources, and make quick world maps.\r\nI recently released the first development version of the package, which is now available on my Github page. The package also has a website containing information on the package’s usage.\r\nIn this article, we will have a look at how countries can be used to work with country name. In particular, we will look in detail at the function country_name(), which can be used to convert country names to different naming conventions or to translate them to different languages. country_name() can identify countries even when they are provided in mixed formats or in different languages. It is robust to small misspellings and recognises many alternative country names and disused official names.\r\n\r\nInstalling and loading the package\r\nSince the package is not yet on CRAN, the development version needs to be downloaded directly from the Github repository. This can be done with the devtools package.\r\n\r\n\r\n# Install and load devtools\r\ninstall.packages(\"devtools\")\r\nlibrary(devtools)\r\n\r\n# Install countries\r\ndevtools::install_github(\"fbellelli/countries\", build_vignettes = TRUE)\r\n\r\n\r\n\r\nThe package can then be loaded normally\r\n\r\n\r\nlibrary(countries)\r\n\r\n\r\n\r\nDealing with country names\r\nThe function country_name() can be used to convert country names to different naming conventions or to translate them to different languages.\r\n\r\n\r\nexample <- c(\"United States\",\"DR Congo\", \"Morocco\")\r\n\r\n# Getting 3-letters ISO code\r\ncountry_name(x= example, to=\"ISO3\")\r\n\r\n\r\n[1] \"USA\" \"COD\" \"MAR\"\r\n\r\n# Translating to spanish\r\ncountry_name(x= example, to=\"name_es\")\r\n\r\n\r\n[1] \"Estados Unidos\"                 \r\n[2] \"República Democrática del Congo\"\r\n[3] \"Marruecos\"                      \r\n\r\nIf multiple arguments are passed to the argument to, the function will output a data.frame object, with one column corresponding to every naming convention.\r\n\r\n\r\n# Requesting translation to French and 2-letter and 3-letter ISO codes\r\ncountry_name(x= example, to=c(\"name_fr\",\"ISO2\",\"ISO3\"))\r\n\r\n\r\n                           name_fr ISO2 ISO3\r\n1                       États-Unis   US  USA\r\n2 République démocratique du Congo   CD  COD\r\n3                            Maroc   MA  MAR\r\n\r\nThe to argument supports all the following naming conventions:\r\n\r\nCODE\r\nDESCRIPTION\r\nsimple\r\nThis is a simple english version of the name containing only ASCII characters. This nomenclature is available for all countries.\r\nISO3\r\n3-letter country codes as defined in ISO standard 3166-1 alpha-3. This nomenclature is available only for the territories in the standard (currently 249 territories).\r\nISO2\r\n2-letter country codes as defined in ISO standard 3166-1 alpha-2. This nomenclature is available only for the territories in the standard (currently 249 territories).\r\nISO_code\r\nNumeric country codes as defined in ISO standard 3166-1 numeric. This country code is the same as the UN’s country number (M49 standard). This nomenclature is available for the territories in the ISO standard (currently 249 countries).\r\nUN_xx\r\nOfficial UN name in 6 official UN languages. Arabic (UN_ar), Chinese (UN_zh), English (UN_en), French (UN_fr), Spanish (UN_es), Russian (UN_ru). This nomenclature is only available for countries in the M49 standard (currently 249 territories).\r\nWTO_xx\r\nOfficial WTO name in 3 official WTO languages: English (WTO_en), French (WTO_fr), Spanish (WTO_es). This nomenclature is only available for WTO members and observers (currently 189 entities).\r\nname_xx\r\nTranslation of ISO country names in 28 different languages: Arabic (name_ar), Bulgarian (name_bg), Czech (name_cs), Danish (name_da), German (name_de), Greek (name_el), English (name_en), Spanish (name_es), Estonian (name_et), Basque (name_eu), Finnish (name_fi), French (name_fr), Hungarian (name_hu), Italian (name_it), Japponease (name_ja), Korean (name_ko), Lithuanian (name_lt), Dutch (name_nl), Norwegian (name_no), Polish (name_po), Portuguese (name_pt), Romenian (name_ro), Russian (name_ru), Slovak (name_sk), Swedish (name_sv), Thai (name_th), Ukranian (name_uk), Chinese simplified (name_zh), Chinese traditional (name_zh-tw)\r\nGTAP\r\nGTAP country and region codes.\r\nall\r\nConverts to all the nomenclatures and languages in this table\r\n\r\nFurther options and warning messages\r\ncountry_name() can identify countries even when they are provided in mixed formats or in different languages. It is robust to small misspellings and recognises many alternative country names and old nomenclatures.\r\n\r\n\r\nfuzzy_example <- c(\"US\",\"C@ète d^Ivoire\",\"Zaire\",\"FYROM\",\"Estados Unidos\",\"ITA\")\r\n\r\ncountry_name(x= fuzzy_example, to=c(\"UN_en\"))\r\n\r\n\r\nMultiple country IDs have been matched to the same country name\r\nSet - verbose - to TRUE for more details\r\n[1] \"United States of America\"        \r\n[2] \"Côte d’Ivoire\"                   \r\n[3] \"Democratic Republic of the Congo\"\r\n[4] \"North Macedonia\"                 \r\n[5] \"United States of America\"        \r\n[6] \"Italy\"                           \r\n\r\nMore information on the country matching process can be obtained by setting verbose=TRUE. The function will print information on:\r\nThe number of unique values provided by the user. In the example below 6 distinct strings have been provided.\r\nHow many country names correspond exactly to the ones in the function’s reference list and how many have been recognised with fuzzy matching. In the example below, \"C@ète d^Ivoire\" is the only name recognised with fuzzy matching. The function’s reference table can be accessed with the command data(country_reference_list).\r\nThe function prints summary statistics on fuzzy matching. The DISTANCE metric refers to the number of insertions, deletions or substitutions necessary to go from the provided string (\"C@ète d^Ivoire\") to the closest reference (\"Côte d'Ivoire\"). Lower DISTANCE statistics indicate more reliable fuzzy matching.\r\n\r\n\r\ncountry_name(x= fuzzy_example, to=c(\"UN_en\"), verbose=TRUE)\r\n\r\n\r\n\r\nIn total 6 unique country identifiers have been found\r\n5/6 have been matched with EXACT matching\r\n1/6 have been matched with FUZZY matching\r\n\r\nFuzzy matching DISTANCE summary:\r\n | Average:  3\r\n | Min: 3 \r\n | Q1: 3 \r\n | Median: 3 \r\n | Q3: 3 \r\n | Max: 3\r\n\r\nMultiple arguments have been matched to the same country name:\r\n  - Estados Unidos : United States of America \r\n  - US : United States of America\r\n[1] \"United States of America\"        \r\n[2] \"Côte d’Ivoire\"                   \r\n[3] \"Democratic Republic of the Congo\"\r\n[4] \"North Macedonia\"                 \r\n[5] \"United States of America\"        \r\n[6] \"Italy\"                           \r\n\r\nIn addition, setting verbose=TRUE will also print additional informations relating to specific warnings that are normally given by the function:\r\nMultiple country IDs have been matched to the same country name: This warning is issued if multiple strings have been matched to the same country. In verbose mode, the strings and corresponding countries will be listed. In the example above, both \"US\" and \"Estados Unidos\" are matched to the same country. If the vector of country names is a unique identifier, this could indicate that some country name was not recognised correctly. The user might consider using custom tables (refer to the next section).\r\nSome country IDs have no match in one or more country naming conventions: indicates that it is impossible to find an exact match for one or more country names with fuzzy_match=TRUE. The user might consider using fuzzy_match=TRUE or custom tables (refer to the next section).\r\nThere is low confidence on the matching of some country names: This warning indicates that some strings have been matched poorly. Thus indicating that the country might have been mididentified. In verbose mode the function will provide a list of problematic strings (see the example below). The user might consider using custom tables to solve this type of issues (refer to the next section).\r\nSome country IDs have no match in one or more country naming conventions: Conversion is requested to a nomenclature for which there is no information on the country. For instance, in the example below “Taiwan” has no correspondence in the UN M49 standard. In verbose mode, the function will print all the country names affected by this problem. The user might consider using custom tables to solve this type of issues (refer to the next section).\r\n\r\n\r\ncountry_name(x= c(\"Taiwan\",\"lsajdèd\"), to=c(\"UN_en\"), verbose=FALSE)\r\n\r\n\r\nSome country IDs have no match in one or more country naming conventions\r\nThere is low confidence on the matching of some country names\r\nSet - verbose - to TRUE for more details\r\n[1] NA                                \r\n[2] \"Lao People's Democratic Republic\"\r\n\r\nAll the information from verbose mode can be accessed by setting ´simplify=FALSE´. This will return a list object containing:\r\n´converted_data´: the normal output of the function\r\n´match_table´: the conversion table with information on the closest match for each country name and distance metrics.\r\n´summary´: summary values for the distance metrics\r\n´warning´: logical value indicating whether a warning is issued by the function\r\n´call´: the arguments passed by the user\r\nUsing custom conversion tables\r\nIn some cases, the user might be unhappy with the naming conversion or no valid conversion might exist for the provided territory. In these cases, it might be useful to tweak the conversion table. The package contains a utility function called ´match_table()´, which can be used to generate conversion tables for small adjustments.\r\n\r\n\r\nexample_custom <- c(\"Siam\",\"Burma\",\"H#@°)Koe2\")\r\n\r\n#suppose we are unhappy with how \"H#@°)Koe2\" is interpreted by the function\r\ncountry_name(x = example_custom, to = \"name_en\")\r\n\r\n\r\nThere is low confidence on the matching of some country names\r\nSet - verbose - to TRUE for more details\r\n[1] \"Thailand\"           \"Myanmar\"            \"Korea, Republic of\"\r\n\r\n#match_table can be used to generate a table for small adjustments\r\ntab <- match_table(x = example_custom, to = \"name_en\")\r\n\r\n\r\nThere is low confidence on the matching of some country names\r\n\r\ntab$name_en[2] <- \"Hong Kong\"\r\n\r\n#which can then be used for conversion\r\ncountry_name(x = example_custom, to = \"name_en\", custom_table = tab)\r\n\r\n\r\n[1] \"Thailand\"  \"Myanmar\"   \"Hong Kong\"\r\n\r\nWork in progress\r\nI am still working on the package. In the near future, the following items will be added to the package:\r\nfunction to test strings on whether they are country names\r\nfunctions to identify columns in dataframes containing country names and date information\r\nfunction for downloading up-to-date information on countries (e.g. currency, language, population, etc.)\r\nfunction for downloading country data for analysis from different sources (e.g. UN, World Bank, FRED, etc.)\r\nfunction to quickly merge country data from different sources\r\nfunction to tag countries based on common criteria (e.g. developing status, World bank income group, geographic region, etc.)\r\nfunction to easily plot chloropleth maps\r\npublish on CRAN\r\n\r\n\r\n\r\n",
    "preview": "posts/2022-02-27-first-version-of-countries/../../images/Countries_logo.png",
    "last_modified": "2022-03-26T00:15:39+01:00",
    "input_file": {},
    "preview_width": 864,
    "preview_height": 1000
  },
  {
    "path": "posts/2021-12-18-mishmash-of-charts/",
    "title": "Mishmash of charts",
    "description": "This article is a selection of charts that I prepared over the last three years.",
    "author": [
      {
        "name": "Francesco S. Bellelli",
        "url": {}
      }
    ],
    "date": "2021-12-18",
    "categories": [
      "economics",
      "other"
    ],
    "contents": "\r\n\r\nContents\r\nTrade war\r\nCOVID-19 decoupling\r\nFishing\r\nFinancial shocks\r\nEconomic activity and carbon emissions\r\nConflicts in history\r\nClimate risks\r\nInternational environmental agreements\r\nEnvironmental policy\r\nUncertainty\r\nEnergy\r\n\r\nTrade war\r\nIn 2019 there was a rapid escalation of trade tensions after Trump imposed tariffs aiming to punish China for its widening trade surplus vis-à-vis the Unites States. I made the following maps for the bank Pictet to illustrate the rapid progression of Chinese exports since its accession to WTO. China progressively becomes a bigger exporter than the United States in almost every market in the world.\r\nLiz Faunce (Financial Times) compilled these maps into a gif and inserted them on an article on this topic. To my surprise, a few months later it got selected among the FT ten charts that tell the story of 2019.\r\n\r\n\r\n\r\nCOVID-19 decoupling\r\nThis charts shows the decoupling of COVID cases and deaths in the UK following the vaccination campaign of 2021. Until then, the death curve followed cases with an approximate lag of two weeks. Each spike in cases corresponded to a spike in deaths (very clear for the January 2021 spike). The mortality rate from COVID plummeted after vaccination roll-out. The July 2021 spike in COVID cases is not followed by a similar surge in the death curves.\r\n\r\n\r\n\r\n\r\nFigure 1: COVID-19 deaths in London decouple from cases thanks to vaccinationData source: Public Health England / Office of National Statistics\r\n\r\n\r\n\r\nFishing\r\nThe following two charts depict the increase in intensity of fishing activity. The first chart is based on some amazing data put together by Global Fishing Watch. They trained a machine learning model to detect the amount of time and type of fishing activity in which vessels engage based on a combination of satellite and vessel tracking data. The image below shows the evolution of fishing hours for different fishing methods between 2012 and 2017. The second chart is based on FAO data of catches and shows that the global volume of catches has remained roughly stable since 1990. This slow down could be linked to the unsustainable level of fishing activity. FAO estimates that 94% of all fish stocks are currently overfished or fished at their maximum sustainable level.\r\n\r\n\r\n\r\nFigure 2: Fishing effort and total catchesData source: Global Fishing Watch\r\n\r\n\r\n\r\n\r\n\r\n\r\nFigure 3: Total global fishing catchesData source: FAO\r\n\r\n\r\n\r\nFinancial shocks\r\nThese long time-series offer a snapshot of the number of financial crises in the world over the last 200 years. They show how financial shocks tend to be cyclical and globalisation lead to economies being synchronised across the world.\r\n\r\n\r\n\r\nFigure 4: Financial cycles from 1800Data source: Reinhart et al. (https://www.hbs.edu/behavioral-finance-and-financial-stability/data/Pages/global.aspx)\r\n\r\n\r\n\r\nEconomic activity and carbon emissions\r\nThe next three charts are about carbon emissions and their link with economic activity. The first chart shows a breakdown of emission by production stage for some of the main food and agriculture products. The data comes from a metadata analysis conducted by Nemecek and Poore (2018) and reveals a considerable heterogeneity across products.\r\n\r\n\r\n\r\nFigure 5: Breakdown of emissions from the food supply chainData source: Nemecek and Poore (2018)\r\n\r\n\r\n\r\nThe second chart shows the correlation between population and carbon emissions of European countries and is a reminder that we are all individually contributing to emissions. Countries above the trend line have a per capita consumption higher than the European average.\r\n\r\n\r\n\r\nFinally, the third chart shows the key role played by technological innovation in curbing emissions. The chart illustrates growth in carbon emissions between 1995 and 2009 for a selection of countries and contrasts it to a scenario in which emission intensity remained constant. I used data from GTAP on emissions and production by ISIC sector to compute the two scenarios.\r\n\r\n\r\n\r\nFigure 6: Growth of carbon emissions 1995-2009 with and without technological improvementData source: GTAP\r\n\r\n\r\n\r\nConflicts in history\r\nAnother long time-series. This time showing the number of active conflicts around the world over the last 600 years. Conclusion: humans have never been a peaceful species.\r\n\r\n\r\n\r\nClimate risks\r\nClimate change will bring an increase in extreme weather events, such as droughts, cyclones and floods. These will constitute an increasing threat, especially for more vulnerable developing countries. The following charts illustrate the increase in average global temperatures, natural hazards and the uneven exposures of countries to climate risks.\r\n\r\n\r\n\r\nFigure 7: Global warmingData source: HadCRUT4 (https://www.metoffice.gov.uk/hadobs/hadcrut4/index.html)\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\nFigure 8: Exposure to natural hazardsData source: World Risk Report 2020\r\n\r\n\r\n\r\nInternational environmental agreements\r\nWe often talk of large multilateral environmental agreements: the Paris Agreement, the Montreal Prorocol on ODS, etc.. However, this is only the tip of the iceberg. There are hundreds of active environmental agreements. Most of these agreements involve a smaller number of countries engaging over regional issues. The two following charts offer a breakdown of over 3000 environmental agreements (data from the IEA database).\r\n\r\n\r\n\r\nFigure 9: International environmental agreements by subjectData source: IEA Database Project (https://iea.uoregon.edu/)\r\n\r\n\r\n\r\n\r\n\r\n\r\nFigure 10: International environmental agreements by year and typeData source: IEA Database Project (https://iea.uoregon.edu/)\r\n\r\n\r\n\r\nEnvironmental policy\r\nThe following two charts are based on the WTO environmental database. This database tracks the environment-related measures notified to the WTO. It contains over 13000 measures and it is exceptional in its broad coverage of countries. As shown below, the number of notified environment-related measures is on the rise, but they are mostly being implemented in middle and high income countries.\r\n\r\n\r\n\r\nFigure 11: Number of environment-related measures notified to the WTOData source: WTO Environmental database (EDB)\r\n\r\n\r\n\r\n\r\n\r\n\r\nFigure 12: Least developmed countries notify less environmental measures to the WTOData source: WTO Environmental database (EDB)\r\n\r\n\r\n\r\nUncertainty\r\nUncertainty on economic policy has always been around. But the last two years have brought uncertainty to an all new level. This is exactly what this index suggests based on wording frequency in newspaper articles published around the world.\r\n\r\n\r\n\r\nFigure 13: Policy uncertainty following the 2019 trade tensions and COVID-19Data source: Global Economic Policy Uncertainty Index\r\n\r\n\r\n\r\nEnergy\r\nWe often give access to electricity as granted, but a large portion of the world population currently lives without electricity. The first charts illustrates the relationship between income and access to electricity. The second chart shows the recent boom in adoption of solar and wind technologies for electricity generation. Once again, poorer nations are lagging behind due to high switching costs.\r\n\r\n\r\n\r\nFigure 14: Electricity access vs incomeData source: World BankNotes: Each point correspond to a coutry in 2017.\r\n\r\n\r\n\r\n\r\n\r\n\r\nFigure 15: Uptake of solar and wind energy by income groupData source: BP Statistical Review of World Energy, World Bank.Notes: The figure shows GDP-weighted average of the share of solar and wind energy in the electricity mic\r\n\r\n\r\n\r\n\r\n\r\n\r\n",
    "preview": "posts/2021-12-18-mishmash-of-charts/../../papers/map pictet.gif",
    "last_modified": "2022-05-14T16:36:32+02:00",
    "input_file": {}
  },
  {
    "path": "posts/2021-11-16-the-world-trade-report-is-out/",
    "title": "The 2021 World Trade Report is out",
    "description": "I had the honour to contribute to the writing of this year's edition of the World Trade Report, the flagship economic publication of the World Trade Organization.  The report explores the role of trade, trade policy and international cooperation in building economic resilience in a world marked by increasing risks. In this article, I briefly outline my contributions on risk trends and policy responses to shocks.",
    "author": [
      {
        "name": "Francesco S. Bellelli",
        "url": {}
      }
    ],
    "date": "2021-11-16",
    "categories": [
      "economics",
      "trade",
      "risk"
    ],
    "contents": "\r\n\r\nContents\r\nKey messages of the report\r\nMy contribution on risks and policy response\r\nThe launch of the report\r\n\r\n\r\n\r\nThe full 2021 World Trade Report is available here.\r\n\r\n\r\n\r\nKey messages of the report\r\nThe COVID-19 pandemic and the prospect of increasingly frequent and more intense natural and man-made disasters raise important questions about the resilience of the global economy to such shocks. The World Trade Report 2021 explores the role of trade, trade policy and international cooperation in building and supporting economic resilience.\r\nThe report conveys three main messages: first, today’s hyper-connected global economy, characterized by deep trade links, has made the world more vulnerable to shocks, but also more resilient to them when they strike; second, policies which aim to increase economic resilience by unwinding trade integration –– for example, by re-shoring production and promoting self-sufficiency — can often have the opposite effect, effectively reducing economic resilience; and third, strengthening economic resilience will require more global cooperation.\r\nMy contribution on risks and policy response\r\nI contributed to writing section B of the report. In particular, I authored the part exploring the sources and trends in risks, and the part on policy responses to shocks.\r\nIn the report, we highlight that risks are constantly evolving and are increasingly interlinked. For example, climate change is driving increases in extreme weather events, such as droughts, cyclones and floods, which can have devastating economic and social effects. Human encroachment on animal habitats can increase the risks of spreading zoonotic diseases, which could potentially lead to another pandemic. Although safer production processes have reduced the frequency of technological and industrial disasters, incidences of cyber-attacks and data fraud are expected to continue to increase. Rising inequality, increasing economic fragility, and growing political uncertainty and geopolitical tensions are augmenting the risk of conflicts and violence. While there is a tendency to look at these risks individually, they can interact with each other and create cascading risks.\r\nThese risks materialise into shocks which have considerable human, economic and environmental damages. The economic policy responses to shocks is usually aimed at cushioning the impact of the shocks. We can decompose economic disruption into: 1) demand shocks, 2) supply shocks and 3) increased uncertainty. In the the report we describe how different policies have been used to tackle these disruptions and note that shocks usually involve a combination of the three elements. Similarly, trade policy response is rarely entirely restrictive or liberalising. On the one hand, protectionism is seen as a way of prioritising domestic economic activity, while, on the the other hand, trade-opening often plays a crucial role in solving sudden demand-supply mismatches and emergency situations.\r\nThe launch of the report\r\n\r\n\r\n\r\n\r\n\r\n",
    "preview": "https://www.wto.org/images/img_bkshop/wtr21_e.jpg",
    "last_modified": "2022-05-13T22:06:38+02:00",
    "input_file": {}
  },
  {
    "path": "posts/2021-10-24-all-you-need-to-know-about-the-paris-agreement-ahead-of-cop26/",
    "title": "All you need to know about the Paris Agreement ahead of COP26",
    "description": "Only one week left to the official start of the COP26 in Glasgow, in which global leaders will meet to take crucial decisions on climate change. Scientific evidence shows that we are running out of time. If we wish to avoid the worst scenario, it's now or never. What will come out of the summit? Will it be a flop or a success? We don't know yet, but this article will quickly get you up to speed with climate talks.",
    "author": [
      {
        "name": "Francesco S. Bellelli",
        "url": {}
      }
    ],
    "date": "2021-10-24",
    "categories": [
      "environment"
    ],
    "contents": "\r\n\r\nContents\r\nWhat is the Paris agreement?\r\nWait … what is climate change?\r\nGreat! We got an agreement. Everything is fine then?\r\nHow does the Paris agreement work?\r\nWhat is COP26 and why is it important?\r\n\r\nWhat is the Paris agreement?\r\nIf you haven’t heard of the Paris agreement you probably just came back from an interplanetary trip, awoke from hibernation experiment, or remained stranded on an island with no means of communication with the outside world for at least six years. So, let me congratulate you for making it here! We are happy to have you back!\r\nDuring your absence, country delegates gathered in Paris to sign a new agreement on climate change. Its goal is simply stated: limit the increase in average temperature to levels “well below 2°C above pre-industrial levels”. While the goal is simply stated, it is not simply reached. Climate change has been called the biggest challenge that humanity has to face.\r\nWait … what is climate change?\r\nIf you haven’t heard of this one, you might have been away longer than you think. Although I think you might have more pressing questions to attend, I won’t leave a question unanswered: Climate change refers to a lasting change in the temperature and weather patterns around the world. Most of human activities directly or indirectly generate greenhouse gases (GHG), such as carbon dioxide or methane, which trap heat in the atmosphere. An increase as small as 2°C in global average temperature is enough to create disruptive changes around the world. Torrential rainfalls, severe droughts, food insecurity, melting glaciers, biodiversity loss, flooding and rise of sea levels are just some of the unpleasant events that scientists have associated with climate change. In short: climate change effects are bad, and the risks and costs associated with it are not fully understood. We should definitively try to avoid it! And that’s what the Paris agreement is meant for. The idea is to avoid these catastrophic events by limit GHG emissions as much as possible and adapting to these changes.\r\n\r\n\r\n\r\nFigure 1: Temperature trend over the last 160 years Source: IPCC 2019 special report on Global warming of 1.5°C\r\n\r\n\r\n\r\nGreat! We got an agreement. Everything is fine then?\r\nAlas, it’s too early to celebrate. We already had two big agreements on climate change: the 1992 UN Framework Convention on Climate Change (UNFCCC), which established the institutions and principles for cooperation on climate change, and the 1997 Kyoto Protocol, which imposed binding emission reduction targets on a handful of developed nations. Yet, judging from the trend in CO\\(_2\\) concentration in the figure below, they were not terribly effective at stopping climate change. If they had, we would not be writing about a third agreement on the same issue.\r\n\r\n\r\n\r\nFigure 2: CO2 concentration in the atmosphere Source: Global Carbon Budget 2020\r\n\r\n\r\n\r\nAdmittedly, our track record is not exceptional. However, this time might be different. The Paris agreement started very well. The international community signalled a strong political engagement by allowing the Paris agreement to enter into force in 2016, just 30 days after it was open for signature — this is impressive given that it took eight years for the ratification and entry into force of the Kyoto Protocol. A crucial role in its early adoption was played by the prompt ratification of the United States — which later decided to pull-out of the agreement, and then again to rejoin it — and China during a joint ceremony. These are the two biggest GHG emitters in the world. To date, 197 countries have signed the agreement, and 190 ratified it. What’s more, the Paris agreements asks all its participants to contribute to reducing emissions by making pledges (more on this in a minute). This is essential because successful climate action requires global engagement and most of GHG emissions growth will take place in developing countries.\r\nWe can call it a good start, but the truth is that all the work still lies ahead. The figure below shows the projected global warming in a scenario in which we reach net zero emissions by 2030 (resulting in 1.5°C warming) and by 2055 (2°C warming). Reaching net zero emissions means that, on balance, the amount of GHG released in the atmosphere needs to be no larger than the GHG removed from the atmosphere. Considering that we emit about 50bn tonnes of CO\\(_2\\)-equivalent GHG, this is no small task! And achieving neutrality before 2030 (or even 2055) is definitively a challenge. One thing is certain: the earlier we act, the more likely we are to succeed.\r\n\r\n\r\n\r\nFigure 3: Paths towards Paris agreement’s goal Source: IPCC 2019 special report on Global warming of 1.5°C\r\n\r\n\r\n\r\nHow does the Paris agreement work?\r\nOverall the experience of the Kyoto Protocol was rather negative. Negotiations were arduous, the protocol engaged only a small number of countries, the entry into force was extremely slow, and its effectiveness in curbing emissions is debatable. Therefore, negotiators decided to opt for a totally different approach for the Paris Agreement. The system introduced by the Paris agreement has a two-layer structure:\r\nA common binding ground that regulates the assessment process and basic formal requirements on accounting and communication of GHG emissions;\r\nA flexible target setting for participants, in which each country is free to establish its objectives and the way it proposes to achieve them. The self-determined goals are called Nationally Determined Contribution (NDC).\r\nThe agreement sets no binding emission targets for the participants and the ratifiers incur no sanction if they do not fulfil their NDC. However, the monitoring and reporting process is binding. In addition, every five years the parties must update their NCDs objectives, which must represent a progress toward the target of the agreement and reflect the “highest possible ambition” (Article 4, Paris Agreement). As of now, the reduction in emissions implied by the sum of all pledges is unable to ensure that the objective of “well below 2°C”is met (see Figure below). However, 2021 marks the fifth year from the entry into force of the agreement. Hence, it’s now time to submit new, more ambitious pledges. Many of these new pledges have already been submitted in the past weeks. You can check out the Climate action tracker website for an overview of NDC submissions.\r\n\r\n\r\n\r\nFigure 4: Current pledges fall short of Paris agreeement’s target Source: Our World in Data\r\n\r\n\r\n\r\nAnother feature of the Paris agreement is that it allows countries to pay for carbon emissions to be reduced abroad and counting these reductions towards its own national targets. This should allow to cut the costs of climate action by curbing emissions where it is most efficient. Finally, the agreement also creates financial mechanisms to support developing countries in meeting their goals. In particular, developed nations promised to provide 100 billion dollars annually from 2020 to 2025 to support the agreement.\r\nWhat is COP26 and why is it important?\r\nEvery year, countries that are members to the UN Framework Convention on Climate Change and the Paris agreement meet to assess their progress and take decisions regarding the implementation of the agreement. The fancy name of these meetings is “Conference of the Parties” — COP for short. This year’s COP will take place in Glasgow and it is the 26th edition of COP (hence COP26).\r\nThis edition is important for multiple reasons. First, this edition marks five years from the entry into force of the agreement. Hence, we should expect new pledges and big announcements, which will provide a guidance for the next five years of implementation. For example, we might expect joint pledges on deforestation, renewable energy and electric cars. Secondly, there are still some sticking points in the implementation rules which need to be negotiated. For example, members still need to define the highly contentious issue of how the carbon trading mechanisms will work in practice. Finally, we also need to find the money for climate action. At the moment, we are still a bit short of the 100bn rich countries had promised to provide by 2020.\r\n\r\n\r\n\r\n",
    "preview": "posts/2021-10-24-all-you-need-to-know-about-the-paris-agreement-ahead-of-cop26/pexels-pixabay-221012.jpg",
    "last_modified": "2021-12-18T22:44:50+01:00",
    "input_file": {}
  },
  {
    "path": "posts/2021-08-15-pandemic-and-the-office-space-market/",
    "title": "How has the pandemic affected the office space market?",
    "description": "In this post I have a look at data from the City of London to understand how the pandemic has impacted the office market.",
    "author": [
      {
        "name": "Francesco S. Bellelli",
        "url": {}
      }
    ],
    "date": "2021-08-15",
    "categories": [
      "economics"
    ],
    "contents": "\r\n\r\n\r\n\r\n\r\n\r\nClick here to open the data dashboard.\r\n\r\n\r\n\r\n\r\n\r\n\r\n",
    "preview": "posts/2021-08-15-pandemic-and-the-office-space-market/city2_preview.jpg",
    "last_modified": "2021-12-18T22:42:46+01:00",
    "input_file": {}
  },
  {
    "path": "posts/2021-07-08-the-fascinating-world-of-voronoi-diagrams/",
    "title": "The fascinating world of Voronoi diagrams",
    "description": "In this article I explain what is a Voronoi diagram and why they are amazing",
    "author": [
      {
        "name": "Francesco S. Bellelli",
        "url": {}
      }
    ],
    "date": "2021-07-08",
    "categories": [
      "maths",
      "other"
    ],
    "contents": "\r\n\r\nContents\r\nWhat is a Voronoi diagram?\r\nVoronoi patterns are ubiquitous\r\nVoronoi patterns in nature\r\nVoronoi pattern in architecture and arts\r\n\r\nMathematical definition and some interesting properties\r\nDelaunay triangulation\r\nLloyd’s relaxation algorithm\r\nHow to construct Voronoi diagrams?\r\nLinks to additional material\r\n\r\n\r\n\r\n\r\nVoronoi diagrams (also known as Dirichlet tesselation or Thiessen polygons) are everywhere in nature. You have encountered them thousands of times, but maybe did not call it this way. Voronoi diagram are simple, yet they have incredible properties which have found applications in fields ranging from cartography, biology, computer science, statistics, archaeology, all way to architecture and arts.\r\nWhat is a Voronoi diagram?\r\nSuppose you have \\(n\\) points scattered on a plane, the Voronoi diagram of those points subdivides the plane in exactly \\(n\\) cells enclosing the portion of the plane that is the closest to the each point. This produces a tessellation that completely covers the plane. As an illustration, in Figure 1, I plotted 100 random points and their corresponding Voronoi diagram. As you can see, every point is enclosed in a cell, whose boundaries are exactly equidistant between two or more points. In other words, all the area enclosed in the cell is closest to the point in the cell than to any other point.\r\n\r\n\r\n\r\nFigure 1: Voronoi diagram from 100 random points in a plane\r\n\r\n\r\n\r\nVoronoi patterns are ubiquitous\r\nVoronoi patterns in nature\r\nThe pattern created by Voronoi diagrams is a common one in nature. In Figure 3, I made a small collage of some naturally occurring Voronoi-like patterns. From microscopic cells in onion skins, to the shell of jackfruits and the coat of giraffes. These patterns are everywhere!\r\nA first reason for their omnipresence is that they form efficient shapes. As we mentioned earlier, Voronoi diagram completely tessellates the plan: hence, all space is used. This is very convenient if you are trying to squeeze as much as possible in a limited space — such as in muscle fibres or bee hives. Secondly, Voronoi diagrams are a spontaneous pattern whenever something is growing at a uniform growth rate from separate points (see Figure 2). For instance, this explains giraffe exhibit such patterns. Giraffe embryos have a scattered distribution of melanin-secreting cells, which is responsible for the dark pigmentation of the giraffe’s spots. Over the course of the gestation these cells release melanin — hence spots radiate outward. Interested reader may refer to this paper, in which the authors use Voronoi diagrams to model computer rendering of spots on animals coats.\r\n\r\n\r\n\r\nFigure 2: A Voronoi diagram is obtained from constant outward growth from dispered pointsSource: Wikipedia\r\n\r\n\r\n\r\n\r\n\r\n\r\nFigure 3: Voronoi patterns are everywhere in nature. (From top-left to bottom right: microscope view of onion skin cells, cross-section of a muscle, garlic bulb, wings of a dragonfly, soap bubbles, close-up of a leaf, giraffes coat patterns, corns, jackfruits hanging from a tree.)\r\n\r\n\r\n\r\nVoronoi pattern in architecture and arts\r\nPerhaps because of their spontaneous “natural” look, or simply because of their mesmerising randomness, Voronoi patterns have intentionally been implemented in human-made structures. An architectural example is the “Water cube” built to house the water sports during the 2008 Beijing Olympics. It features Voronoi diagrams on its ceiling and façades (Figure 4). The Voronoi diagrams were chosen because they recall bubbles1. This analogy is very clear at night, when the entire façade is illuminated in blue and comes alive.\r\n\r\n\r\n\r\nFigure 4: Water cube in Beijing\r\n\r\n\r\n\r\nBut Chinese appreciation of Voronoi pattern is surely older than this building. Guan and Ge ware from the Song dynasty have a distinctive crackled glaze. Ceramics can easily crack during the cooling process, however the crackles from the Guan and Ge ware are different — they are intentional. They are sought after because of their aesthetic qualities. Thanks to the Voronoi-like patterns on their surface, each piece is unique. To date, this is one of the most imitated styles of porcelain (Figure 5).\r\n\r\n\r\n\r\nFigure 5: Guan and Ge wares\r\n\r\n\r\n\r\nVoronoi diagrams are also common in graphic arts for creating “abstract” patterns. I think they make excellent background images. For example, I created the thumbnail of this post by generating random points and constructing a Voronoi diagram. Then, I coloured each cell based on the distance of its point from a randomly selected spot in the box (Figure 6). Endless “abstract” backgrounds images could be generated this way.\r\n\r\n\r\n\r\nFigure 6: Coloured Voronoi diagram\r\n\r\n\r\n\r\nMathematical definition and some interesting properties\r\nSo far, we have presented a simple two-dimensional Voronoi diagram. However, the same type of structure can be generalised to an \\(n\\)-dimensional space. Suppose \\(P=\\{p_1,p_2,...,p_m\\}\\) is a set of \\(m\\) points in our n-dimensional space. Then, the space can be partitioned in \\(m\\) Voronoi cells, \\(V_i\\), containing all points in \\(\\mathbb{R}^n\\) that are closer to \\(p_i\\) than to any other point.\r\n\\[V_i = \\left\\{x : \\forall j \\neq i, d(x, p_i) \\leq d(x,p_j)\\right\\} \\text{, with } i,j \\in \\{1,2,...,m\\}\\] Where the function \\(d(x,y)\\) gives the distance (\\(a\\)) between its two arguments. Typically, the Euclidean distance is used (\\(l^2\\) distance):\r\n\\[d(x,y)=||x-y||_2=\\sqrt{\\sum_{k=1}^{n}(x_k-y_k)^2}\\] However, Voronoi diagrams could be designed using other distance functions. For instance, Figure 7 shows a Voronoi diagram obtained with the Manhattan or cityblock distance (\\(l^1\\) distance). The Manahattan distance is the distance between two points if you had to follow a regular grid — such as the city blocks of Manhattan. The result is a more “boxy” Voronoi diagram. \\[d(x,y)=||x-y||_1=\\sum_{k=1}^{n}{|x_k-y_k|}\\]\r\n\r\n\r\n\r\nFigure 7: Euclidean and Manhattan distanceSource:Johnson Hsieh\r\n\r\n\r\n\r\n\r\n\r\n\r\nFigure 8: Comparison of Voronoi diagrams using the Euclidean (left) and Manhattan (right) distance for a same set of pointsSource: Wikipedia\r\n\r\n\r\n\r\nEuclidean distance is the most common distance measure in scientific applications of the Voronoi diagram. It also has the advantage of generating Voronoi cells that are convex. That is to say, if you take any two points within a cell, the line that connects the two points will lie entirely within the cell.\r\nFinally, it should also be noted that Voronoi diagrams are tightly linked with the k-nearest neighbours algorithm (k-NN) — a very popular algorithm in classification, regression and clustering problems. The algorithm uses the \\(k\\) closest examples in the training dataset to make value predictions. Since the Voronoi diagrams partitions the space in polygons containing the closest points to each seed, the edges of Voronoi cells correspond exactly to the decision boundaries of a simple 1-nearest neighbour problem.\r\nDelaunay triangulation\r\nIf you take each of the points from a Voronoi diagram and link it with the points in its neighbouring cells, you will obtain a graph called Delaunay triangulation. In mathematical terms, the Delaunay triangulation is the dual graph of the Voronoi diagram. In the Figure below, a Voronoi diagram (black) and Delaunay triangulation (grey) is plotted from a set of points. By moving the mouse over the image, one can explore how they are affected by a new point.\r\n\r\n\r\n\r\n\r\nFigure 9: Voronoi diagram and Delaunay triangulationSource: r2d3\r\n\r\n\r\n\r\nDelaunay triangulation is just as amazing as Voronoi diagrams. As the name suggests, it produces a set of triangles linking our points. These triangles are such that if one were to draw a circle across the vertices of these triangles, there would be no other point inside the circle (See Figure 10). Moreover, Delaunay triangulation also has the property of maximising the smallest angle of in the triangles of the triangulation. Hence, Delaunay triangulation tends to avoid triangles with acute angles.\r\n\r\n\r\n\r\nFigure 10: Delaunay triangles are constructed such that no point falls inside the circle circumscribing each triangleSource: Wikipedia\r\n\r\n\r\n\r\nThese properties make it very useful in modelling surfaces and objects from a set of points. For instance, the Delaunay triangulation is used to generate meshes for the finite element method and in facial recognition, construct 3D models for computer animations and model terrain in GIS analysis.\r\n\r\n\r\n\r\nFigure 11: Delaunay triangulation is used to produce meshes for facial recognitionSource: Learn OpenCV\r\n\r\n\r\n\r\nLloyd’s relaxation algorithm\r\nLlyod’s algorithm is a useful algorithm related to Voronoi diagrams. The algorithm consists in repeatedly alternating between constructing Voronoi diagrams and finding the centroids (i.e. center of mass) of each cell (See Figure 12). At each iteration, the algorithm spaces the points apart and produces more homogeneous Voronoi cells.\r\n\r\n\r\n\r\nFigure 12: Steps in Lloyd’s relaxation algorithm\r\n\r\n\r\n\r\nAfter a few iterations, the cells will already have a “rounder” aspect and points will be more evenly distributed. This is illustrated in the figure below, in which I have plotted the first 30 iterations of the Lloyd’s algorithm for a random set of points. For each point, I also record their starting position (grey hollow circle) to better trace the movement of each cell. For high number of iterations, the diagram tends to converge towards a stable Voronoi diagram in which every seed is also the centroid of the cell — also known as the centroidal Voronoi diagram. Interestingly, in 2D, Voronoi cells will tend to turn into hexagons because they provide the most efficient way of of packing shapes in a plane. As any bee building their hive can certify, hexagonal cells have two big advantages: 1) they ensure no empty space is left between cells (i.e. tessellates the plane), and 2) hexagons offer the highest ratio between surface and perimeter of the cell. This so-called Honeycomb conjecture, took mathematicians two-thousand years to prove.\r\n\r\n\r\n\r\nFigure 13: 30 iterations of the Lloyd’s algorithm\r\n\r\n\r\n\r\nIn data science, Lloyd’s algorithm is at the basis of k-means clustering — one of the most popular clustering algorithms. k-means clustering is typically initiated by taking \\(k\\) random “centroids” in space. Then, data points are grouped in \\(k\\) clusters by alternating between 1) assigning data points to the closest “centroid” (this is equivalent to building a Voronoi diagram for the centroid and checking which point are inside the cell) and 2) updating the centroid by calculating the mean of the points inside each cell (See Figure 14).\r\n\r\n\r\n\r\nFigure 14: k-means clusteringSoruce: Wikipedia\r\n\r\n\r\n\r\nBesides data science, Lloyd’s algorithm is used in a variety of applications. For instance, it is very common in quantization and lossy data compression algorithms (e.g. Lloyd-Max algorithm). It is also very useful whenever one wants random points that are nicely spaced. For instance, it could be used to smooth meshes generated from the Delaunay triangulation, for dithering images, or as a basis for procedural maps generation in video games.\r\nHow to construct Voronoi diagrams?\r\nOne could construct Voronoi diagrams by building each cell one by one. If one extends the bisector of the segments linking every combination of points, it is possible to obtain the outline of Voronoi cells (Figure 15). However, this technique is quite inefficient. Considering there are \\(\\frac{1}{2}(1-n)n\\) combinations of points, the complexity of such algorithm would increase quadratically with the number of points.\r\n\r\n\r\n\r\nFigure 15: Construction of Voronoi cellsSource: Roberto Tamassia\r\n\r\n\r\n\r\nMore efficient alternatives have been proposed. For example, the Sweep line algorithm builds Voronoi cells progressively by sequentially using binary search tree and priority queue operations (Figure 16). A good description of this algorithm can be found here. Another way of constructing Voronoi diagrams, is to first build Delaunay triangulations. Once the triangulation is obtained, extending the bisectors of the triangle edges leads to the Voronoi diagram (Figure 17). Delaunay triangulation can be obtained without the need of considering every pair of points. For instance, an efficient technique consists in projecting the points on a paraboloid in a higher dimension. Re-projecting back the convex hull onto the original space gives the Delaunay triangulation (Figure 18)\r\n\r\n\r\n\r\nFigure 16: Sweep line algorithmSource: Wikipedia\r\n\r\n\r\n\r\n\r\n\r\n\r\nFigure 17: Construction of Voronoi diagramsSource: Giulia Andreucci\r\n\r\n\r\n\r\n\r\n\r\n\r\nFigure 18: Using the convex hull method for constructing Delaunay triangulationSource: Danny Sleator\r\n\r\n\r\n\r\nA discussion of different algorithms for computing Voronoi diagram and their complexity is available here, here, and here. New algorithms are continuously being proposed to improve computation efficiency in different circumstances (e.g. Yan et al. 2011, Qin et al. 2017). There are also techniques requiring constant time that generate approximate Voronoi diagrams (e.g. Jump flooding algorithm).\r\nLinks to additional material\r\nThis article tells the story of how Voronoi diagrams were used by John Snow to show the link between water pumps and the transmission of Cholera during the 1854 London outbreak.\r\nAmil Patel has a phenomenal blog on game development. I highly recommend his posts on procedural map generation with Voronoi diagrams.\r\nThis post by David Austin gives a great explanation of the Sweep line algorithm for computing Voronoi diagrams.\r\nThis nice looking map by Jason Davies is a Voronoi diagram of the location of airports around the world.\r\nSpatial Tessellations: Concepts and Applications of Voronoi Diagrams is a bible on Voronoi diagrams. If you have any doubt about Voronoi diagrams, you will certainly find an answer here.\r\nThese slides from Vincent Legat have some beautiful drawings for different construction algorithms.\r\nVoronoi diagrams are commonly used to model trees in forests (e.g. Abellanas et al. 2016, Bohler et al. 2018).\r\nVoronoi diagrams can also be used to determine robot’s paths. Check these articles: article 1, article 2.\r\nVoronoi diagrams have thousand of applications. From modelling trees in a forest to planning robot paths. In this article I barely scratched the surface. These links contain lists of interesting applications: link 1, link 2, link3, link4, link 5.\r\n\r\nTo be more precise, the “Water cube” patterns are inspired from Weaire-Phelan bubbles. However, these are directly obtainable as Voronoi diagram.↩︎\r\n",
    "preview": "posts/2021-07-08-the-fascinating-world-of-voronoi-diagrams/voronoi_animation2.gif",
    "last_modified": "2022-05-24T22:01:21+02:00",
    "input_file": {}
  },
  {
    "path": "posts/2021-06-20-a-package-for-country-data/",
    "title": "A package for country data",
    "description": "I am working on an R package designed to quickly wrangle, merge and explore country data",
    "author": [
      {
        "name": "Francesco S. Bellelli",
        "url": {}
      }
    ],
    "date": "2021-06-20",
    "categories": [
      "coding"
    ],
    "contents": "\r\n\r\n\r\nThe development version of the package is available here.\r\n\r\n\r\n\r\nAs an economist, I often work with country-level data coming from different sources. GDP series from the IMF, monetary data from central banks, trade data from WTO, CO2 emissions from the IEA, survey data from national agencies, etc.. Pooling all this data together is often a laborious task because countries’ naming conventions are never the same.\r\nTo make things easier, I am writing an R package to deal with this type of data. Ideally, the user should be able to merge country data files with a unique line of command. The package will offer functionalities to:\r\nConvert country names to a common nomenclature (e.g. M49 standard or ISO-3 codes)\r\nTranslate country names to different languages\r\nMerge country data in a unique table by recognising and matching different country nomenclatures\r\nSupport the merging of country data with multiple identifiers (e.g. panel data or country-sector data)\r\nEasily download and merge data from online public data (e.g. World Bank data, FRED, etc.)\r\nAutomatically generate interactive visualisations to explore country data\r\n\r\n\r\n\r\n",
    "preview": "https://cdn.britannica.com/13/129613-131-30279F20/Flags-world-flags-Country-history-blog-travel-2009.jpg",
    "last_modified": "2022-01-11T11:26:28+01:00",
    "input_file": {}
  },
  {
    "path": "posts/2021-04-03-tilemaster-a-strategy-game-in-shiny/",
    "title": "TileMaster: a strategy game in Shiny",
    "description": "I created a small strategy game with RStudios' Shiny platform. If it can run a data dashboard, why not a strategy game?",
    "author": [
      {
        "name": "Francesco S. Bellelli",
        "url": {}
      }
    ],
    "date": "2021-04-03",
    "categories": [
      "coding"
    ],
    "contents": "\r\n\r\n\r\n\r\n\r\n\r\nClick here to open the game Tile master in your browser. The complete code of the shiny app is available on Github.\r\n\r\n\r\n\r\nAfter a look at the amazing gallery of dashboards and interactive data visualisations from Shiny apps, I decided that I had to explore its functionalities by trying a project on my own.\r\nShiny allows R users to quickly build and share simple apps that run on browsers. They are ideal for data visualisation. It is really easy to create interactive charts and combine them in a beautiful dashboards. So why not trying to plot some interesting economic data? I should have thought about this a bit longer. For some inexplicable reason, I decided it would be interesting to implement a strategy board game on a shiny app.\r\nIt was a challenging project. It took some time, and a lot more coding than originally planned, but eventually I managed to implement a playable game with Shiny. For the moment I didn’t write down the games’ rules and didn’t include a tutorial. So, if you don’t mind figuring the rules out by trial and error, feel free to give it a try! No fun is guaranteed.\r\nThis game was an enriching journey. I ended up exploring all sorts of unexpected subjects: from path finding algorithms and Delaunay triangulation to advanced game developing concepts. I also thoroughly enjoyed building the AI for this game. Given the strategic complexity of the game — and being the first AI I ever built — I am quite pleased with the final result. I experimented with different AI approaches, programmatic, machine learning and hybrids. In its final version, the basic AI decision process is a hybrid between a finite-state machine and a utility-based system. I then improved it by training machine learning models to evaluate the AI’s moves.\r\nI implemented many functionalities in the app. Users can save and load games, generate random maps with customisable parameters, select AI difficulty level and even play in a shared-screen multiplayer mode. In the end, it was a great learning project!\r\n\r\n\r\n\r\n",
    "preview": "posts/2021-04-03-tilemaster-a-strategy-game-in-shiny/../../images/tilemaster_screenshot.png",
    "last_modified": "2022-01-11T11:53:14+01:00",
    "input_file": {},
    "preview_width": 1599,
    "preview_height": 1531
  },
  {
    "path": "posts/2021-03-20-how-to-increase-participation-in-environmental-agreements/",
    "title": "How to increase participation in environmental agreements?",
    "description": "Understanding the determinants of participation in environmental agreements can help us frame more successful agreements. In this article, I discuss the economic theory and empirical evidence on this topic.",
    "author": [
      {
        "name": "Francesco S. Bellelli",
        "url": {}
      }
    ],
    "date": "2021-03-20",
    "categories": [
      "environment",
      "economics"
    ],
    "contents": "\r\n\r\nContents\r\nEnvironmental agreements and economic theory\r\nEmpirical evidence\r\n\r\n\r\n\r\n\r\nFigure 1: Number of multilateral environmental agreements by year Data from Mitchell (2020)\r\n\r\n\r\n\r\nThe world is facing significant environmental challenges, most of which are transboundary. Air pollution, contamination of lakes and rivers, global warming, biodiversity loss, deforestation, desertification, or overfishing are all problems that cross national borders and require international cooperation. Currently, the primary cooperative tools at our disposal are international environmental agreements, such as the Paris agreement on climate change, the CITES agreement on the trade of endangered species, or the Montreal protocol on ozone-depleting substances.\r\nOver the last fifty years, the number of environmental agreements has exploded (Figure 1). To date, more than 3,000 environmental agreements have been identified (Mitchell 2020) embodying cooperation on the most disparate environmental issues (Figure 2). Some agreements are successful, while others fail. Some attract universal participation, while others die on the negotiation table. Now more than ever, environmental agreements play a crucial role in improving environmental protection worldwide. Hence, the following questions are of great interest to economists: What motivates participation in environmental agreements? How can participation in environmental agreements be increased? Is there any factor at the national level that systematically enhance participation rates? If so, how can policy makers intervene to improve the likelihood of solving transboundary and global environmental issues?\r\n\r\n\r\n\r\nFigure 2: Number of agreements by subject Data from Mitchell (2020)\r\n\r\n\r\n\r\nEnvironmental agreements and economic theory\r\nThese questions have been addressed in economic research mostly using game-theoretical approaches in models that predict both the optimal emission abatement and participation levels in international agreements. In these models, countries contend with a considerable incentive to free-ride because the benefits of the agreement are usually considered non-excludable and non-rival. Hence, the conclusions of classic game-theoretical models are generally pessimistic on the capacity to solve environmental problems. In these models, wide participation in agreements can only be achieved with low abatement targets that fall short of the social optimum. This outlook originates from the core assumptions of these models, which frame treaty participation as a one-off non-cooperative choice — just like in a prisoner’s dilemma.\r\nLater works largely confirmed the free-riding incentive existing in treaty participation, with some improvement in the participation outlook. For example, participation can be improved if participants can offer side transfers. Under the right circumstances also the inclusion of penalties, trade restriction, minimum participation rules and permit trading schemes can considerably boost participation. Moreover, in repeated games — which allow countries to join the agreement in different moments — the result are generally more optimistic than in one-off games.\r\nEmpirical evidence\r\nThanks to the collection of large catalogues of environmental agreements (e.g. Mitchell 2020; CIESIN 2013), scholars can now look at these questions from an empirical perspective. Several findings emerge from this line of enquiry.\r\nFirst of all, the success of an agreement depends primarily on its content. This is by far the most important factor. More stringent agreement tend to deter participation, but there are some type of clauses (e.g.monitoring and enforcement rules, minimum participation rules, technological transfers, financial assistance) which can deliver stronger environmental commitment without penalising participation. Moreover, in Bellelli, Scarpa, and Aftab (2021), I show that regional agreements attract consistently higher ratification rates — on average the probability of joining a regional agreement is 2.5 times higher than for international agreements.\r\n\r\n\r\n\r\nFigure 3: Number of IEA ratifications by 2017 Data from Bellelli, Scarpa, and Aftab (2021)\r\n\r\n\r\n\r\nSo, design of the agreement matters. But this does not tell the whole story. As shown in the map above, participation varies not only between environmental agreements, but also between countries. And these differences are not random, rather, they seem to be clustered geographically, suggesting that political and economic factors are at play. The level of income, the quality of political institutions, the trade profile of the country, electoral and constitutional rules, the economic interests of domestic agents, are all factors that may influence a countries’ participation in international agreements.\r\nFinally, participation choices are seen as a strategic moves, which do not only depend on the characteristics of the country and treaty, but also on the behaviour of foreign nations. While we would theoretically expect a free-riding attitude, empirical evidence suggests that free-riding incentives are mitigated by the presence of international linkages. Empirical findings show that ratification likelihood increases when foreign nations decide to participate in treaties. This is particularly true in the case of large nations and countries that are in the same geographical area or income bracket. The empirical literature agrees that this effect is partly explained by the existence of economic and political ties between countries, which create interdependence and reputational costs for non-participation.\r\n\r\nMore information on this topic may be found in:\r\nBellelli, F.S., Scarpa, R. and Aftab, A. (2021) The joining dilemma: A survey of the empirical literature on environmental treaty participation. Review of Environmental Economics and Policy. (Forthcoming) PDF Appendix\r\nBellelli, F.S., Scarpa, R. and Aftab, A. Interest groups and participation in international environmental agreements. Working paper. Available from https://fbellelli.com/research.html. PDF\r\n\r\n\r\n\r\n\r\nBellelli, Francesco Saverio, Riccardo Scarpa, and Ashar Aftab. 2021. “Interest Groups and Participation in International Environmental Agreements.” Working Paper.\r\n\r\n\r\nCIESIN. 2013. “Environmental Treaties and Resource Indicators (ENTRI).” Center for International Earth Science Information Network.\r\n\r\n\r\nMitchell, R. B. 2020. “International Environmental Agreements Database Project.” University of Oregon.\r\n\r\n\r\n\r\n\r\n",
    "preview": "posts/2021-03-20-how-to-increase-participation-in-environmental-agreements/map-number-ratifications.png",
    "last_modified": "2021-12-18T22:30:02+01:00",
    "input_file": {},
    "preview_width": 7017,
    "preview_height": 4209
  },
  {
    "path": "posts/2021-01-27-watercolours/",
    "title": "Watercolours",
    "description": "A gallery displaying some of the artistic creations of Francesco and Lily",
    "author": [
      {
        "name": "Francesco S. Bellelli",
        "url": {}
      },
      {
        "name": "Lily Runkun Tian",
        "url": {}
      }
    ],
    "date": "2021-01-27",
    "categories": [
      "other"
    ],
    "contents": "\r\n\r\n\r\n\r\n\r\nClick on any picture to enlarge it\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n",
    "preview": "posts/2021-01-27-watercolours/paintings/squirrel.jpeg",
    "last_modified": "2021-12-18T22:27:35+01:00",
    "input_file": {}
  },
  {
    "path": "posts/2021-01-20-mappa-licita-naturale/",
    "title": "Mappa licita naturale",
    "description": "Mappa di un sistema di licita naturale lungo-corto a bridge",
    "author": [
      {
        "name": "Francesco S. Bellelli",
        "url": {}
      }
    ],
    "date": "2021-01-20",
    "categories": [
      "other"
    ],
    "contents": "\r\n\r\n\r\n\r\n\r\n\r\nScaricare immagine: SVG\r\n\r\n\r\n\r\nVersione zoomabile\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n",
    "preview": "posts/2021-01-20-mappa-licita-naturale/BRIDGE sistema naturale.svg",
    "last_modified": "2021-12-18T22:25:27+01:00",
    "input_file": {}
  }
]
